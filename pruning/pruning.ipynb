{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from torch.nn.utils import prune\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = \"training_output/runs/detect/train/weights/best.pt\"\n",
    "OUTPUT_PATH = \"training_output/runs/detect/train/weights/model_pruned.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2024-12-11T09:39:49.714782',\n",
       " 'version': '8.3.49',\n",
       " 'license': 'AGPL-3.0 (https://ultralytics.com/license)',\n",
       " 'docs': 'https://docs.ultralytics.com',\n",
       " 'epoch': -1,\n",
       " 'best_fitness': None,\n",
       " 'model': DetectionModel(\n",
       "   (model): Sequential(\n",
       "     (0): Conv(\n",
       "       (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (1): Conv(\n",
       "       (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (2): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (3): Conv(\n",
       "       (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (4): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (5): Conv(\n",
       "       (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (6): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (7): Conv(\n",
       "       (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (8): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (9): SPPF(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "     (10): Upsample(scale_factor=2.0, mode='nearest')\n",
       "     (11): Concat()\n",
       "     (12): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (13): Upsample(scale_factor=2.0, mode='nearest')\n",
       "     (14): Concat()\n",
       "     (15): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (16): Conv(\n",
       "       (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (17): Concat()\n",
       "     (18): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (19): Conv(\n",
       "       (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (20): Concat()\n",
       "     (21): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (22): Detect(\n",
       "       (cv2): ModuleList(\n",
       "         (0): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (1): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (2): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (cv3): ModuleList(\n",
       "         (0): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (1): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (2): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (dfl): DFL(\n",
       "         (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'ema': None,\n",
       " 'updates': None,\n",
       " 'optimizer': None,\n",
       " 'train_args': {'task': 'detect',\n",
       "  'mode': 'train',\n",
       "  'model': 'yolov8n.pt',\n",
       "  'data': '/kaggle/input/cityperson/data.yaml',\n",
       "  'epochs': 200,\n",
       "  'time': None,\n",
       "  'patience': 100,\n",
       "  'batch': 16,\n",
       "  'imgsz': 640,\n",
       "  'save': True,\n",
       "  'save_period': -1,\n",
       "  'cache': False,\n",
       "  'device': 0,\n",
       "  'workers': 8,\n",
       "  'project': None,\n",
       "  'name': 'train',\n",
       "  'exist_ok': False,\n",
       "  'pretrained': True,\n",
       "  'optimizer': 'auto',\n",
       "  'verbose': True,\n",
       "  'seed': 0,\n",
       "  'deterministic': True,\n",
       "  'single_cls': False,\n",
       "  'rect': False,\n",
       "  'cos_lr': False,\n",
       "  'close_mosaic': 10,\n",
       "  'resume': False,\n",
       "  'amp': True,\n",
       "  'fraction': 1.0,\n",
       "  'profile': False,\n",
       "  'freeze': None,\n",
       "  'multi_scale': False,\n",
       "  'overlap_mask': True,\n",
       "  'mask_ratio': 4,\n",
       "  'dropout': 0.0,\n",
       "  'val': True,\n",
       "  'split': 'val',\n",
       "  'save_json': False,\n",
       "  'save_hybrid': False,\n",
       "  'conf': None,\n",
       "  'iou': 0.7,\n",
       "  'max_det': 300,\n",
       "  'half': False,\n",
       "  'dnn': False,\n",
       "  'plots': True,\n",
       "  'source': None,\n",
       "  'vid_stride': 1,\n",
       "  'stream_buffer': False,\n",
       "  'visualize': False,\n",
       "  'augment': False,\n",
       "  'agnostic_nms': False,\n",
       "  'classes': None,\n",
       "  'retina_masks': False,\n",
       "  'embed': None,\n",
       "  'show': False,\n",
       "  'save_frames': False,\n",
       "  'save_txt': False,\n",
       "  'save_conf': False,\n",
       "  'save_crop': False,\n",
       "  'show_labels': True,\n",
       "  'show_conf': True,\n",
       "  'show_boxes': True,\n",
       "  'line_width': None,\n",
       "  'format': 'torchscript',\n",
       "  'keras': False,\n",
       "  'optimize': False,\n",
       "  'int8': False,\n",
       "  'dynamic': False,\n",
       "  'simplify': True,\n",
       "  'opset': None,\n",
       "  'workspace': None,\n",
       "  'nms': False,\n",
       "  'lr0': 0.01,\n",
       "  'lrf': 0.01,\n",
       "  'momentum': 0.937,\n",
       "  'weight_decay': 0.0005,\n",
       "  'warmup_epochs': 3.0,\n",
       "  'warmup_momentum': 0.8,\n",
       "  'warmup_bias_lr': 0.0,\n",
       "  'box': 7.5,\n",
       "  'cls': 0.5,\n",
       "  'dfl': 1.5,\n",
       "  'pose': 12.0,\n",
       "  'kobj': 1.0,\n",
       "  'nbs': 64,\n",
       "  'hsv_h': 0.015,\n",
       "  'hsv_s': 0.7,\n",
       "  'hsv_v': 0.4,\n",
       "  'degrees': 0.0,\n",
       "  'translate': 0.1,\n",
       "  'scale': 0.5,\n",
       "  'shear': 0.0,\n",
       "  'perspective': 0.0,\n",
       "  'flipud': 0.0,\n",
       "  'fliplr': 0.5,\n",
       "  'bgr': 0.0,\n",
       "  'mosaic': 1.0,\n",
       "  'mixup': 0.0,\n",
       "  'copy_paste': 0.0,\n",
       "  'copy_paste_mode': 'flip',\n",
       "  'auto_augment': 'randaugment',\n",
       "  'erasing': 0.4,\n",
       "  'crop_fraction': 1.0,\n",
       "  'cfg': None,\n",
       "  'tracker': 'botsort.yaml'},\n",
       " 'train_metrics': {'metrics/precision(B)': 0.80279,\n",
       "  'metrics/recall(B)': 0.51299,\n",
       "  'metrics/mAP50(B)': 0.62425,\n",
       "  'metrics/mAP50-95(B)': 0.37667,\n",
       "  'val/box_loss': 1.28536,\n",
       "  'val/cls_loss': 0.843,\n",
       "  'val/dfl_loss': 0.94951,\n",
       "  'fitness': 0.40143},\n",
       " 'train_results': {'epoch': [1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158,\n",
       "   159,\n",
       "   160,\n",
       "   161,\n",
       "   162,\n",
       "   163,\n",
       "   164,\n",
       "   165,\n",
       "   166,\n",
       "   167,\n",
       "   168,\n",
       "   169,\n",
       "   170,\n",
       "   171,\n",
       "   172,\n",
       "   173,\n",
       "   174,\n",
       "   175,\n",
       "   176,\n",
       "   177,\n",
       "   178,\n",
       "   179,\n",
       "   180,\n",
       "   181,\n",
       "   182,\n",
       "   183,\n",
       "   184,\n",
       "   185,\n",
       "   186,\n",
       "   187,\n",
       "   188,\n",
       "   189,\n",
       "   190,\n",
       "   191,\n",
       "   192,\n",
       "   193,\n",
       "   194,\n",
       "   195,\n",
       "   196],\n",
       "  'time': [67.7035,\n",
       "   130.385,\n",
       "   191.747,\n",
       "   252.768,\n",
       "   313.608,\n",
       "   374.398,\n",
       "   435.08,\n",
       "   496.312,\n",
       "   557.42,\n",
       "   618.506,\n",
       "   679.605,\n",
       "   740.558,\n",
       "   801.674,\n",
       "   862.924,\n",
       "   923.394,\n",
       "   984.434,\n",
       "   1045.45,\n",
       "   1106.38,\n",
       "   1167.22,\n",
       "   1228.17,\n",
       "   1289.14,\n",
       "   1350.0,\n",
       "   1410.83,\n",
       "   1471.44,\n",
       "   1532.3,\n",
       "   1593.47,\n",
       "   1654.76,\n",
       "   1716.15,\n",
       "   1777.26,\n",
       "   1838.27,\n",
       "   1899.23,\n",
       "   1959.83,\n",
       "   2020.44,\n",
       "   2081.32,\n",
       "   2142.34,\n",
       "   2203.52,\n",
       "   2264.4,\n",
       "   2325.6,\n",
       "   2386.87,\n",
       "   2447.99,\n",
       "   2508.63,\n",
       "   2569.7,\n",
       "   2630.53,\n",
       "   2691.49,\n",
       "   2752.71,\n",
       "   2813.78,\n",
       "   2875.21,\n",
       "   2936.34,\n",
       "   2997.03,\n",
       "   3057.64,\n",
       "   3118.67,\n",
       "   3179.42,\n",
       "   3240.49,\n",
       "   3301.3,\n",
       "   3361.97,\n",
       "   3422.82,\n",
       "   3483.92,\n",
       "   3544.49,\n",
       "   3605.61,\n",
       "   3666.53,\n",
       "   3727.45,\n",
       "   3788.41,\n",
       "   3849.46,\n",
       "   3910.58,\n",
       "   3971.75,\n",
       "   4032.55,\n",
       "   4092.61,\n",
       "   4152.94,\n",
       "   4213.49,\n",
       "   4274.02,\n",
       "   4334.46,\n",
       "   4394.85,\n",
       "   4455.52,\n",
       "   4516.16,\n",
       "   4577.22,\n",
       "   4638.05,\n",
       "   4698.71,\n",
       "   4759.1,\n",
       "   4819.91,\n",
       "   4880.45,\n",
       "   4941.01,\n",
       "   5001.41,\n",
       "   5061.96,\n",
       "   5122.71,\n",
       "   5183.24,\n",
       "   5243.69,\n",
       "   5304.21,\n",
       "   5364.61,\n",
       "   5425.09,\n",
       "   5485.44,\n",
       "   5545.74,\n",
       "   5606.55,\n",
       "   5667.26,\n",
       "   5728.17,\n",
       "   5788.9,\n",
       "   5849.51,\n",
       "   5909.98,\n",
       "   5970.42,\n",
       "   6030.54,\n",
       "   6091.03,\n",
       "   6151.57,\n",
       "   6212.07,\n",
       "   6272.46,\n",
       "   6332.87,\n",
       "   6393.6,\n",
       "   6453.99,\n",
       "   6514.13,\n",
       "   6574.98,\n",
       "   6635.48,\n",
       "   6695.91,\n",
       "   6756.37,\n",
       "   6816.87,\n",
       "   6877.77,\n",
       "   6939.36,\n",
       "   7000.83,\n",
       "   7061.92,\n",
       "   7123.45,\n",
       "   7184.85,\n",
       "   7245.63,\n",
       "   7306.33,\n",
       "   7367.08,\n",
       "   7427.96,\n",
       "   7488.51,\n",
       "   7549.23,\n",
       "   7610.31,\n",
       "   7671.48,\n",
       "   7732.37,\n",
       "   7793.25,\n",
       "   7854.19,\n",
       "   7915.27,\n",
       "   7976.14,\n",
       "   8036.44,\n",
       "   8097.23,\n",
       "   8158.09,\n",
       "   8219.16,\n",
       "   8280.13,\n",
       "   8341.41,\n",
       "   8402.69,\n",
       "   8464.15,\n",
       "   8525.49,\n",
       "   8586.11,\n",
       "   8648.13,\n",
       "   8710.64,\n",
       "   8772.56,\n",
       "   8834.85,\n",
       "   8897.12,\n",
       "   8959.08,\n",
       "   9021.23,\n",
       "   9082.79,\n",
       "   9143.4,\n",
       "   9204.28,\n",
       "   9264.65,\n",
       "   9325.22,\n",
       "   9385.98,\n",
       "   9446.86,\n",
       "   9507.93,\n",
       "   9568.99,\n",
       "   9629.72,\n",
       "   9690.69,\n",
       "   9751.39,\n",
       "   9811.88,\n",
       "   9872.78,\n",
       "   9933.73,\n",
       "   9994.61,\n",
       "   10055.1,\n",
       "   10115.8,\n",
       "   10176.8,\n",
       "   10237.5,\n",
       "   10298.1,\n",
       "   10359.2,\n",
       "   10420.2,\n",
       "   10481.0,\n",
       "   10541.9,\n",
       "   10603.0,\n",
       "   10664.4,\n",
       "   10725.4,\n",
       "   10786.4,\n",
       "   10847.1,\n",
       "   10907.8,\n",
       "   10968.7,\n",
       "   11029.4,\n",
       "   11090.3,\n",
       "   11151.3,\n",
       "   11212.1,\n",
       "   11273.1,\n",
       "   11333.7,\n",
       "   11394.8,\n",
       "   11455.9,\n",
       "   11516.7,\n",
       "   11577.9,\n",
       "   11638.7,\n",
       "   11697.7,\n",
       "   11756.7,\n",
       "   11815.4,\n",
       "   11874.5,\n",
       "   11933.6],\n",
       "  'train/box_loss': [2.00148,\n",
       "   1.85867,\n",
       "   1.88402,\n",
       "   1.92447,\n",
       "   1.85442,\n",
       "   1.81398,\n",
       "   1.78342,\n",
       "   1.75023,\n",
       "   1.72574,\n",
       "   1.70554,\n",
       "   1.69557,\n",
       "   1.67951,\n",
       "   1.66921,\n",
       "   1.64625,\n",
       "   1.63197,\n",
       "   1.62325,\n",
       "   1.60729,\n",
       "   1.60853,\n",
       "   1.59743,\n",
       "   1.59884,\n",
       "   1.57625,\n",
       "   1.57635,\n",
       "   1.56849,\n",
       "   1.55401,\n",
       "   1.55259,\n",
       "   1.55643,\n",
       "   1.5439,\n",
       "   1.53228,\n",
       "   1.53203,\n",
       "   1.53102,\n",
       "   1.51792,\n",
       "   1.51856,\n",
       "   1.51355,\n",
       "   1.50132,\n",
       "   1.5004,\n",
       "   1.48908,\n",
       "   1.49035,\n",
       "   1.48592,\n",
       "   1.47983,\n",
       "   1.46863,\n",
       "   1.47467,\n",
       "   1.46173,\n",
       "   1.47234,\n",
       "   1.45879,\n",
       "   1.45955,\n",
       "   1.45684,\n",
       "   1.46201,\n",
       "   1.45356,\n",
       "   1.43584,\n",
       "   1.43863,\n",
       "   1.44586,\n",
       "   1.44059,\n",
       "   1.43122,\n",
       "   1.42706,\n",
       "   1.43184,\n",
       "   1.4256,\n",
       "   1.42812,\n",
       "   1.42398,\n",
       "   1.41222,\n",
       "   1.40875,\n",
       "   1.41991,\n",
       "   1.40674,\n",
       "   1.39635,\n",
       "   1.40066,\n",
       "   1.40072,\n",
       "   1.40086,\n",
       "   1.40133,\n",
       "   1.39625,\n",
       "   1.38265,\n",
       "   1.38515,\n",
       "   1.38605,\n",
       "   1.38482,\n",
       "   1.39176,\n",
       "   1.37529,\n",
       "   1.37803,\n",
       "   1.37719,\n",
       "   1.36826,\n",
       "   1.36844,\n",
       "   1.37125,\n",
       "   1.37041,\n",
       "   1.35798,\n",
       "   1.34797,\n",
       "   1.35571,\n",
       "   1.36105,\n",
       "   1.34836,\n",
       "   1.34957,\n",
       "   1.35318,\n",
       "   1.34777,\n",
       "   1.34183,\n",
       "   1.33535,\n",
       "   1.33541,\n",
       "   1.33934,\n",
       "   1.33721,\n",
       "   1.3326,\n",
       "   1.32047,\n",
       "   1.33346,\n",
       "   1.32437,\n",
       "   1.33017,\n",
       "   1.31908,\n",
       "   1.32063,\n",
       "   1.31107,\n",
       "   1.31818,\n",
       "   1.327,\n",
       "   1.32312,\n",
       "   1.30572,\n",
       "   1.30062,\n",
       "   1.31052,\n",
       "   1.30847,\n",
       "   1.30573,\n",
       "   1.30115,\n",
       "   1.29502,\n",
       "   1.2943,\n",
       "   1.29472,\n",
       "   1.285,\n",
       "   1.28721,\n",
       "   1.28986,\n",
       "   1.28643,\n",
       "   1.28836,\n",
       "   1.28092,\n",
       "   1.28064,\n",
       "   1.27337,\n",
       "   1.27644,\n",
       "   1.27474,\n",
       "   1.27855,\n",
       "   1.27187,\n",
       "   1.25982,\n",
       "   1.25495,\n",
       "   1.25953,\n",
       "   1.2567,\n",
       "   1.25512,\n",
       "   1.25782,\n",
       "   1.25423,\n",
       "   1.24657,\n",
       "   1.25178,\n",
       "   1.24724,\n",
       "   1.23804,\n",
       "   1.25156,\n",
       "   1.23169,\n",
       "   1.23737,\n",
       "   1.23564,\n",
       "   1.23289,\n",
       "   1.22259,\n",
       "   1.22653,\n",
       "   1.22816,\n",
       "   1.22886,\n",
       "   1.21736,\n",
       "   1.22753,\n",
       "   1.21314,\n",
       "   1.22318,\n",
       "   1.21324,\n",
       "   1.21581,\n",
       "   1.20926,\n",
       "   1.20598,\n",
       "   1.21224,\n",
       "   1.2123,\n",
       "   1.20113,\n",
       "   1.20073,\n",
       "   1.18839,\n",
       "   1.19885,\n",
       "   1.19319,\n",
       "   1.19335,\n",
       "   1.19521,\n",
       "   1.18043,\n",
       "   1.19612,\n",
       "   1.18781,\n",
       "   1.18549,\n",
       "   1.18057,\n",
       "   1.17252,\n",
       "   1.17157,\n",
       "   1.17548,\n",
       "   1.17372,\n",
       "   1.17757,\n",
       "   1.16184,\n",
       "   1.17104,\n",
       "   1.17077,\n",
       "   1.16735,\n",
       "   1.16079,\n",
       "   1.15386,\n",
       "   1.15494,\n",
       "   1.14889,\n",
       "   1.15318,\n",
       "   1.14419,\n",
       "   1.14932,\n",
       "   1.14897,\n",
       "   1.1472,\n",
       "   1.13387,\n",
       "   1.1454,\n",
       "   1.14197,\n",
       "   1.13889,\n",
       "   1.13633,\n",
       "   1.12296,\n",
       "   1.09479,\n",
       "   1.09082,\n",
       "   1.09653,\n",
       "   1.09404,\n",
       "   1.08274],\n",
       "  'train/cls_loss': [2.13188,\n",
       "   1.59034,\n",
       "   1.52863,\n",
       "   1.52447,\n",
       "   1.43985,\n",
       "   1.37788,\n",
       "   1.34715,\n",
       "   1.32113,\n",
       "   1.28768,\n",
       "   1.26176,\n",
       "   1.26188,\n",
       "   1.23824,\n",
       "   1.22744,\n",
       "   1.21408,\n",
       "   1.19737,\n",
       "   1.18611,\n",
       "   1.16912,\n",
       "   1.16879,\n",
       "   1.16111,\n",
       "   1.15943,\n",
       "   1.13692,\n",
       "   1.13466,\n",
       "   1.12455,\n",
       "   1.12049,\n",
       "   1.11762,\n",
       "   1.11509,\n",
       "   1.10528,\n",
       "   1.07972,\n",
       "   1.08843,\n",
       "   1.08936,\n",
       "   1.07586,\n",
       "   1.07502,\n",
       "   1.07287,\n",
       "   1.05456,\n",
       "   1.05321,\n",
       "   1.0497,\n",
       "   1.05042,\n",
       "   1.04898,\n",
       "   1.03501,\n",
       "   1.02105,\n",
       "   1.03293,\n",
       "   1.02535,\n",
       "   1.02972,\n",
       "   1.01907,\n",
       "   1.01461,\n",
       "   1.01495,\n",
       "   1.019,\n",
       "   1.01352,\n",
       "   0.99754,\n",
       "   0.99939,\n",
       "   1.00374,\n",
       "   1.00168,\n",
       "   0.99163,\n",
       "   0.9895,\n",
       "   0.99692,\n",
       "   0.98617,\n",
       "   0.99167,\n",
       "   0.98328,\n",
       "   0.97027,\n",
       "   0.97185,\n",
       "   0.98225,\n",
       "   0.964,\n",
       "   0.96353,\n",
       "   0.95702,\n",
       "   0.95859,\n",
       "   0.96015,\n",
       "   0.95199,\n",
       "   0.96202,\n",
       "   0.94299,\n",
       "   0.94659,\n",
       "   0.94401,\n",
       "   0.94923,\n",
       "   0.944,\n",
       "   0.93477,\n",
       "   0.9384,\n",
       "   0.93585,\n",
       "   0.9316,\n",
       "   0.9305,\n",
       "   0.92122,\n",
       "   0.92963,\n",
       "   0.91582,\n",
       "   0.91306,\n",
       "   0.9138,\n",
       "   0.91824,\n",
       "   0.91045,\n",
       "   0.91322,\n",
       "   0.90977,\n",
       "   0.90949,\n",
       "   0.90236,\n",
       "   0.89864,\n",
       "   0.90089,\n",
       "   0.90645,\n",
       "   0.89519,\n",
       "   0.89966,\n",
       "   0.88602,\n",
       "   0.88998,\n",
       "   0.88996,\n",
       "   0.88941,\n",
       "   0.88057,\n",
       "   0.88271,\n",
       "   0.87333,\n",
       "   0.8861,\n",
       "   0.88516,\n",
       "   0.87557,\n",
       "   0.87199,\n",
       "   0.86267,\n",
       "   0.86926,\n",
       "   0.86801,\n",
       "   0.86571,\n",
       "   0.86095,\n",
       "   0.86226,\n",
       "   0.86048,\n",
       "   0.85261,\n",
       "   0.85336,\n",
       "   0.85411,\n",
       "   0.84972,\n",
       "   0.84612,\n",
       "   0.85038,\n",
       "   0.84721,\n",
       "   0.84146,\n",
       "   0.8406,\n",
       "   0.83876,\n",
       "   0.84225,\n",
       "   0.83838,\n",
       "   0.83723,\n",
       "   0.82816,\n",
       "   0.82735,\n",
       "   0.82788,\n",
       "   0.83089,\n",
       "   0.82286,\n",
       "   0.82378,\n",
       "   0.81911,\n",
       "   0.82026,\n",
       "   0.81708,\n",
       "   0.81512,\n",
       "   0.81104,\n",
       "   0.81529,\n",
       "   0.80338,\n",
       "   0.80593,\n",
       "   0.80797,\n",
       "   0.80214,\n",
       "   0.79331,\n",
       "   0.799,\n",
       "   0.79683,\n",
       "   0.79454,\n",
       "   0.78858,\n",
       "   0.79875,\n",
       "   0.79243,\n",
       "   0.78653,\n",
       "   0.78455,\n",
       "   0.78449,\n",
       "   0.78355,\n",
       "   0.77625,\n",
       "   0.78274,\n",
       "   0.78235,\n",
       "   0.77769,\n",
       "   0.77022,\n",
       "   0.77043,\n",
       "   0.77213,\n",
       "   0.77531,\n",
       "   0.77111,\n",
       "   0.76968,\n",
       "   0.75746,\n",
       "   0.76831,\n",
       "   0.76715,\n",
       "   0.76349,\n",
       "   0.7612,\n",
       "   0.75706,\n",
       "   0.75579,\n",
       "   0.75621,\n",
       "   0.75657,\n",
       "   0.75359,\n",
       "   0.74503,\n",
       "   0.75017,\n",
       "   0.74664,\n",
       "   0.74509,\n",
       "   0.73835,\n",
       "   0.73916,\n",
       "   0.74059,\n",
       "   0.73246,\n",
       "   0.73819,\n",
       "   0.73086,\n",
       "   0.73027,\n",
       "   0.73228,\n",
       "   0.73785,\n",
       "   0.72026,\n",
       "   0.72844,\n",
       "   0.72765,\n",
       "   0.73011,\n",
       "   0.7224,\n",
       "   0.71852,\n",
       "   0.70106,\n",
       "   0.69233,\n",
       "   0.692,\n",
       "   0.69148,\n",
       "   0.68411],\n",
       "  'train/dfl_loss': [1.18057,\n",
       "   1.11154,\n",
       "   1.13299,\n",
       "   1.14229,\n",
       "   1.12136,\n",
       "   1.10638,\n",
       "   1.09752,\n",
       "   1.0861,\n",
       "   1.08003,\n",
       "   1.06683,\n",
       "   1.06825,\n",
       "   1.06013,\n",
       "   1.0549,\n",
       "   1.05755,\n",
       "   1.04845,\n",
       "   1.0401,\n",
       "   1.03771,\n",
       "   1.04143,\n",
       "   1.03726,\n",
       "   1.03167,\n",
       "   1.02872,\n",
       "   1.0325,\n",
       "   1.02597,\n",
       "   1.02123,\n",
       "   1.02357,\n",
       "   1.0225,\n",
       "   1.01301,\n",
       "   1.01289,\n",
       "   1.01307,\n",
       "   1.00758,\n",
       "   1.01032,\n",
       "   1.00808,\n",
       "   1.00145,\n",
       "   1.00479,\n",
       "   0.99646,\n",
       "   0.99538,\n",
       "   1.00092,\n",
       "   0.9946,\n",
       "   0.99288,\n",
       "   0.99194,\n",
       "   0.9928,\n",
       "   0.98987,\n",
       "   0.99141,\n",
       "   0.98622,\n",
       "   0.98407,\n",
       "   0.98629,\n",
       "   0.9881,\n",
       "   0.98023,\n",
       "   0.98264,\n",
       "   0.98149,\n",
       "   0.9791,\n",
       "   0.9804,\n",
       "   0.97739,\n",
       "   0.9772,\n",
       "   0.98046,\n",
       "   0.97645,\n",
       "   0.97767,\n",
       "   0.97794,\n",
       "   0.97147,\n",
       "   0.96768,\n",
       "   0.97132,\n",
       "   0.96961,\n",
       "   0.96978,\n",
       "   0.96725,\n",
       "   0.97133,\n",
       "   0.96824,\n",
       "   0.9663,\n",
       "   0.96569,\n",
       "   0.96668,\n",
       "   0.96525,\n",
       "   0.96313,\n",
       "   0.9646,\n",
       "   0.96267,\n",
       "   0.96016,\n",
       "   0.96233,\n",
       "   0.96128,\n",
       "   0.95662,\n",
       "   0.96157,\n",
       "   0.95575,\n",
       "   0.95915,\n",
       "   0.95379,\n",
       "   0.95111,\n",
       "   0.95181,\n",
       "   0.95258,\n",
       "   0.95335,\n",
       "   0.95266,\n",
       "   0.95363,\n",
       "   0.95222,\n",
       "   0.94921,\n",
       "   0.95063,\n",
       "   0.94818,\n",
       "   0.95235,\n",
       "   0.94742,\n",
       "   0.94414,\n",
       "   0.94674,\n",
       "   0.94763,\n",
       "   0.94426,\n",
       "   0.94682,\n",
       "   0.94426,\n",
       "   0.94643,\n",
       "   0.9424,\n",
       "   0.94158,\n",
       "   0.94566,\n",
       "   0.94009,\n",
       "   0.94133,\n",
       "   0.93822,\n",
       "   0.93717,\n",
       "   0.9441,\n",
       "   0.94061,\n",
       "   0.93984,\n",
       "   0.93495,\n",
       "   0.93719,\n",
       "   0.93509,\n",
       "   0.93269,\n",
       "   0.93369,\n",
       "   0.9328,\n",
       "   0.93145,\n",
       "   0.93386,\n",
       "   0.93379,\n",
       "   0.93206,\n",
       "   0.9298,\n",
       "   0.93181,\n",
       "   0.93124,\n",
       "   0.93103,\n",
       "   0.93097,\n",
       "   0.92972,\n",
       "   0.92687,\n",
       "   0.92991,\n",
       "   0.92859,\n",
       "   0.92531,\n",
       "   0.92756,\n",
       "   0.92357,\n",
       "   0.92466,\n",
       "   0.92641,\n",
       "   0.92513,\n",
       "   0.92232,\n",
       "   0.92374,\n",
       "   0.92117,\n",
       "   0.9193,\n",
       "   0.92005,\n",
       "   0.91825,\n",
       "   0.9183,\n",
       "   0.91889,\n",
       "   0.9202,\n",
       "   0.91927,\n",
       "   0.91587,\n",
       "   0.91716,\n",
       "   0.91554,\n",
       "   0.91559,\n",
       "   0.91353,\n",
       "   0.91611,\n",
       "   0.91314,\n",
       "   0.91361,\n",
       "   0.91472,\n",
       "   0.91315,\n",
       "   0.91125,\n",
       "   0.91348,\n",
       "   0.90891,\n",
       "   0.91129,\n",
       "   0.91492,\n",
       "   0.91086,\n",
       "   0.90943,\n",
       "   0.90891,\n",
       "   0.90914,\n",
       "   0.91002,\n",
       "   0.90922,\n",
       "   0.90697,\n",
       "   0.90719,\n",
       "   0.90514,\n",
       "   0.90848,\n",
       "   0.90389,\n",
       "   0.90495,\n",
       "   0.9037,\n",
       "   0.90407,\n",
       "   0.90568,\n",
       "   0.90637,\n",
       "   0.90426,\n",
       "   0.89994,\n",
       "   0.90239,\n",
       "   0.90184,\n",
       "   0.9026,\n",
       "   0.90155,\n",
       "   0.90049,\n",
       "   0.89907,\n",
       "   0.89978,\n",
       "   0.8964,\n",
       "   0.89882,\n",
       "   0.89699,\n",
       "   0.89721,\n",
       "   0.89707,\n",
       "   0.89532,\n",
       "   0.88961,\n",
       "   0.88853,\n",
       "   0.88707,\n",
       "   0.88695,\n",
       "   0.88636],\n",
       "  'metrics/precision(B)': [0.65627,\n",
       "   0.67565,\n",
       "   0.53777,\n",
       "   0.64565,\n",
       "   0.65494,\n",
       "   0.62593,\n",
       "   0.65142,\n",
       "   0.68762,\n",
       "   0.68026,\n",
       "   0.70402,\n",
       "   0.70933,\n",
       "   0.73413,\n",
       "   0.70183,\n",
       "   0.69979,\n",
       "   0.69223,\n",
       "   0.69742,\n",
       "   0.69053,\n",
       "   0.68737,\n",
       "   0.72567,\n",
       "   0.71092,\n",
       "   0.7372,\n",
       "   0.76886,\n",
       "   0.7241,\n",
       "   0.7922,\n",
       "   0.75408,\n",
       "   0.72888,\n",
       "   0.73937,\n",
       "   0.70078,\n",
       "   0.75859,\n",
       "   0.76209,\n",
       "   0.74633,\n",
       "   0.7543,\n",
       "   0.73452,\n",
       "   0.73275,\n",
       "   0.76421,\n",
       "   0.76787,\n",
       "   0.7683,\n",
       "   0.73967,\n",
       "   0.75262,\n",
       "   0.76343,\n",
       "   0.774,\n",
       "   0.75581,\n",
       "   0.7556,\n",
       "   0.74964,\n",
       "   0.78287,\n",
       "   0.79104,\n",
       "   0.76564,\n",
       "   0.747,\n",
       "   0.74759,\n",
       "   0.77731,\n",
       "   0.77429,\n",
       "   0.74999,\n",
       "   0.7628,\n",
       "   0.76354,\n",
       "   0.79052,\n",
       "   0.77083,\n",
       "   0.78348,\n",
       "   0.77333,\n",
       "   0.74898,\n",
       "   0.74293,\n",
       "   0.76979,\n",
       "   0.73912,\n",
       "   0.77033,\n",
       "   0.78177,\n",
       "   0.73758,\n",
       "   0.73217,\n",
       "   0.76397,\n",
       "   0.75026,\n",
       "   0.79822,\n",
       "   0.80488,\n",
       "   0.813,\n",
       "   0.77091,\n",
       "   0.76333,\n",
       "   0.75366,\n",
       "   0.77145,\n",
       "   0.78951,\n",
       "   0.78642,\n",
       "   0.7627,\n",
       "   0.7631,\n",
       "   0.7503,\n",
       "   0.73542,\n",
       "   0.76633,\n",
       "   0.72027,\n",
       "   0.76244,\n",
       "   0.78159,\n",
       "   0.78049,\n",
       "   0.76561,\n",
       "   0.79505,\n",
       "   0.79602,\n",
       "   0.76893,\n",
       "   0.78299,\n",
       "   0.76139,\n",
       "   0.76623,\n",
       "   0.7416,\n",
       "   0.78542,\n",
       "   0.80279,\n",
       "   0.78997,\n",
       "   0.78536,\n",
       "   0.77368,\n",
       "   0.7738,\n",
       "   0.79301,\n",
       "   0.79566,\n",
       "   0.79516,\n",
       "   0.79405,\n",
       "   0.80264,\n",
       "   0.81108,\n",
       "   0.78746,\n",
       "   0.77678,\n",
       "   0.78057,\n",
       "   0.78679,\n",
       "   0.77579,\n",
       "   0.76057,\n",
       "   0.79761,\n",
       "   0.7902,\n",
       "   0.77716,\n",
       "   0.8075,\n",
       "   0.81378,\n",
       "   0.81374,\n",
       "   0.80224,\n",
       "   0.79863,\n",
       "   0.79033,\n",
       "   0.78897,\n",
       "   0.80512,\n",
       "   0.81182,\n",
       "   0.78564,\n",
       "   0.76408,\n",
       "   0.75965,\n",
       "   0.77361,\n",
       "   0.77235,\n",
       "   0.77408,\n",
       "   0.78023,\n",
       "   0.75803,\n",
       "   0.78336,\n",
       "   0.77662,\n",
       "   0.76602,\n",
       "   0.76562,\n",
       "   0.78885,\n",
       "   0.79453,\n",
       "   0.79177,\n",
       "   0.8045,\n",
       "   0.81971,\n",
       "   0.81953,\n",
       "   0.81927,\n",
       "   0.81771,\n",
       "   0.82303,\n",
       "   0.80123,\n",
       "   0.80687,\n",
       "   0.79834,\n",
       "   0.79914,\n",
       "   0.80788,\n",
       "   0.80658,\n",
       "   0.80661,\n",
       "   0.80099,\n",
       "   0.78596,\n",
       "   0.76353,\n",
       "   0.79018,\n",
       "   0.79092,\n",
       "   0.78431,\n",
       "   0.79531,\n",
       "   0.79362,\n",
       "   0.78779,\n",
       "   0.79141,\n",
       "   0.78083,\n",
       "   0.78092,\n",
       "   0.78654,\n",
       "   0.78207,\n",
       "   0.77813,\n",
       "   0.78275,\n",
       "   0.79652,\n",
       "   0.79482,\n",
       "   0.78334,\n",
       "   0.78704,\n",
       "   0.78569,\n",
       "   0.78637,\n",
       "   0.7835,\n",
       "   0.78538,\n",
       "   0.78822,\n",
       "   0.78799,\n",
       "   0.78541,\n",
       "   0.78873,\n",
       "   0.78884,\n",
       "   0.78755,\n",
       "   0.78486,\n",
       "   0.78471,\n",
       "   0.7794,\n",
       "   0.77778,\n",
       "   0.77674,\n",
       "   0.77311,\n",
       "   0.77264,\n",
       "   0.77122,\n",
       "   0.77205,\n",
       "   0.77463,\n",
       "   0.77748,\n",
       "   0.77513,\n",
       "   0.77202,\n",
       "   0.77326],\n",
       "  'metrics/recall(B)': [0.42064,\n",
       "   0.40955,\n",
       "   0.35158,\n",
       "   0.39889,\n",
       "   0.41816,\n",
       "   0.41141,\n",
       "   0.42532,\n",
       "   0.41758,\n",
       "   0.44307,\n",
       "   0.44759,\n",
       "   0.43414,\n",
       "   0.45315,\n",
       "   0.44434,\n",
       "   0.44004,\n",
       "   0.44202,\n",
       "   0.47217,\n",
       "   0.45408,\n",
       "   0.46604,\n",
       "   0.44852,\n",
       "   0.46614,\n",
       "   0.44944,\n",
       "   0.4564,\n",
       "   0.47475,\n",
       "   0.45455,\n",
       "   0.46793,\n",
       "   0.47217,\n",
       "   0.48685,\n",
       "   0.48122,\n",
       "   0.48794,\n",
       "   0.47841,\n",
       "   0.47897,\n",
       "   0.47845,\n",
       "   0.47356,\n",
       "   0.4949,\n",
       "   0.463,\n",
       "   0.4833,\n",
       "   0.468,\n",
       "   0.49536,\n",
       "   0.48933,\n",
       "   0.48495,\n",
       "   0.48289,\n",
       "   0.49351,\n",
       "   0.49814,\n",
       "   0.50093,\n",
       "   0.4782,\n",
       "   0.48794,\n",
       "   0.49165,\n",
       "   0.50232,\n",
       "   0.49583,\n",
       "   0.49814,\n",
       "   0.50757,\n",
       "   0.50696,\n",
       "   0.49583,\n",
       "   0.50371,\n",
       "   0.4884,\n",
       "   0.50139,\n",
       "   0.48933,\n",
       "   0.50162,\n",
       "   0.50652,\n",
       "   0.50669,\n",
       "   0.50881,\n",
       "   0.51716,\n",
       "   0.50092,\n",
       "   0.49861,\n",
       "   0.52146,\n",
       "   0.51479,\n",
       "   0.51067,\n",
       "   0.51252,\n",
       "   0.49629,\n",
       "   0.4949,\n",
       "   0.49,\n",
       "   0.50974,\n",
       "   0.52507,\n",
       "   0.51577,\n",
       "   0.51438,\n",
       "   0.50105,\n",
       "   0.50464,\n",
       "   0.51345,\n",
       "   0.52319,\n",
       "   0.51206,\n",
       "   0.52783,\n",
       "   0.5187,\n",
       "   0.53144,\n",
       "   0.51716,\n",
       "   0.51953,\n",
       "   0.51289,\n",
       "   0.52269,\n",
       "   0.51278,\n",
       "   0.51531,\n",
       "   0.52319,\n",
       "   0.51042,\n",
       "   0.5218,\n",
       "   0.52365,\n",
       "   0.53803,\n",
       "   0.51299,\n",
       "   0.51299,\n",
       "   0.5116,\n",
       "   0.51252,\n",
       "   0.51716,\n",
       "   0.51725,\n",
       "   0.50232,\n",
       "   0.50696,\n",
       "   0.50557,\n",
       "   0.50928,\n",
       "   0.51345,\n",
       "   0.49981,\n",
       "   0.51577,\n",
       "   0.51577,\n",
       "   0.51252,\n",
       "   0.50836,\n",
       "   0.5116,\n",
       "   0.51567,\n",
       "   0.50696,\n",
       "   0.50974,\n",
       "   0.50835,\n",
       "   0.50603,\n",
       "   0.50557,\n",
       "   0.50603,\n",
       "   0.51299,\n",
       "   0.51322,\n",
       "   0.51067,\n",
       "   0.51855,\n",
       "   0.50788,\n",
       "   0.50788,\n",
       "   0.51507,\n",
       "   0.52458,\n",
       "   0.5292,\n",
       "   0.52551,\n",
       "   0.52244,\n",
       "   0.52285,\n",
       "   0.5167,\n",
       "   0.53471,\n",
       "   0.51531,\n",
       "   0.51438,\n",
       "   0.52458,\n",
       "   0.52319,\n",
       "   0.51067,\n",
       "   0.50881,\n",
       "   0.51206,\n",
       "   0.50788,\n",
       "   0.50191,\n",
       "   0.50278,\n",
       "   0.50251,\n",
       "   0.50139,\n",
       "   0.50232,\n",
       "   0.51206,\n",
       "   0.51113,\n",
       "   0.51484,\n",
       "   0.51391,\n",
       "   0.51067,\n",
       "   0.51345,\n",
       "   0.5146,\n",
       "   0.51711,\n",
       "   0.52134,\n",
       "   0.52968,\n",
       "   0.51763,\n",
       "   0.5167,\n",
       "   0.51994,\n",
       "   0.51484,\n",
       "   0.51546,\n",
       "   0.51999,\n",
       "   0.52089,\n",
       "   0.52319,\n",
       "   0.52273,\n",
       "   0.52273,\n",
       "   0.52458,\n",
       "   0.52319,\n",
       "   0.52412,\n",
       "   0.51746,\n",
       "   0.51948,\n",
       "   0.5232,\n",
       "   0.52087,\n",
       "   0.5218,\n",
       "   0.52134,\n",
       "   0.5218,\n",
       "   0.52108,\n",
       "   0.52041,\n",
       "   0.51994,\n",
       "   0.52116,\n",
       "   0.52226,\n",
       "   0.52155,\n",
       "   0.52087,\n",
       "   0.52285,\n",
       "   0.52238,\n",
       "   0.52505,\n",
       "   0.52365,\n",
       "   0.52412,\n",
       "   0.52458,\n",
       "   0.52319,\n",
       "   0.52412,\n",
       "   0.52458,\n",
       "   0.52597,\n",
       "   0.52597,\n",
       "   0.52505,\n",
       "   0.52644,\n",
       "   0.52551],\n",
       "  'metrics/mAP50(B)': [0.4795,\n",
       "   0.47938,\n",
       "   0.38718,\n",
       "   0.46049,\n",
       "   0.48255,\n",
       "   0.47049,\n",
       "   0.49195,\n",
       "   0.49409,\n",
       "   0.50957,\n",
       "   0.53134,\n",
       "   0.51236,\n",
       "   0.5389,\n",
       "   0.53402,\n",
       "   0.53089,\n",
       "   0.53236,\n",
       "   0.54582,\n",
       "   0.5427,\n",
       "   0.55103,\n",
       "   0.54368,\n",
       "   0.55297,\n",
       "   0.55236,\n",
       "   0.55571,\n",
       "   0.55882,\n",
       "   0.5684,\n",
       "   0.56433,\n",
       "   0.56399,\n",
       "   0.57657,\n",
       "   0.5687,\n",
       "   0.58135,\n",
       "   0.57885,\n",
       "   0.5727,\n",
       "   0.57561,\n",
       "   0.57197,\n",
       "   0.58149,\n",
       "   0.57249,\n",
       "   0.58687,\n",
       "   0.57985,\n",
       "   0.58547,\n",
       "   0.58388,\n",
       "   0.58506,\n",
       "   0.58105,\n",
       "   0.59353,\n",
       "   0.59759,\n",
       "   0.5958,\n",
       "   0.58877,\n",
       "   0.59108,\n",
       "   0.59545,\n",
       "   0.58891,\n",
       "   0.58969,\n",
       "   0.59997,\n",
       "   0.60215,\n",
       "   0.60165,\n",
       "   0.59701,\n",
       "   0.60432,\n",
       "   0.59921,\n",
       "   0.59597,\n",
       "   0.59578,\n",
       "   0.60052,\n",
       "   0.60242,\n",
       "   0.59829,\n",
       "   0.60629,\n",
       "   0.61082,\n",
       "   0.60208,\n",
       "   0.60501,\n",
       "   0.60883,\n",
       "   0.60726,\n",
       "   0.61478,\n",
       "   0.61227,\n",
       "   0.61036,\n",
       "   0.60801,\n",
       "   0.60886,\n",
       "   0.61409,\n",
       "   0.6141,\n",
       "   0.61478,\n",
       "   0.61271,\n",
       "   0.61088,\n",
       "   0.61055,\n",
       "   0.61194,\n",
       "   0.61661,\n",
       "   0.61,\n",
       "   0.61403,\n",
       "   0.62239,\n",
       "   0.61298,\n",
       "   0.61586,\n",
       "   0.61953,\n",
       "   0.61553,\n",
       "   0.61957,\n",
       "   0.61945,\n",
       "   0.62291,\n",
       "   0.62669,\n",
       "   0.62194,\n",
       "   0.62494,\n",
       "   0.62629,\n",
       "   0.62337,\n",
       "   0.62411,\n",
       "   0.62425,\n",
       "   0.62054,\n",
       "   0.62228,\n",
       "   0.62542,\n",
       "   0.62145,\n",
       "   0.61636,\n",
       "   0.61699,\n",
       "   0.61831,\n",
       "   0.61894,\n",
       "   0.62122,\n",
       "   0.6196,\n",
       "   0.622,\n",
       "   0.61877,\n",
       "   0.61617,\n",
       "   0.6165,\n",
       "   0.6168,\n",
       "   0.61791,\n",
       "   0.62067,\n",
       "   0.62178,\n",
       "   0.61988,\n",
       "   0.62237,\n",
       "   0.62322,\n",
       "   0.62231,\n",
       "   0.6213,\n",
       "   0.6196,\n",
       "   0.62087,\n",
       "   0.62443,\n",
       "   0.62436,\n",
       "   0.62335,\n",
       "   0.62435,\n",
       "   0.62122,\n",
       "   0.62532,\n",
       "   0.62432,\n",
       "   0.6226,\n",
       "   0.62107,\n",
       "   0.62112,\n",
       "   0.62148,\n",
       "   0.62206,\n",
       "   0.62043,\n",
       "   0.62033,\n",
       "   0.61908,\n",
       "   0.6196,\n",
       "   0.61774,\n",
       "   0.61768,\n",
       "   0.61803,\n",
       "   0.61903,\n",
       "   0.61846,\n",
       "   0.61732,\n",
       "   0.6174,\n",
       "   0.61758,\n",
       "   0.62114,\n",
       "   0.61991,\n",
       "   0.62034,\n",
       "   0.61994,\n",
       "   0.61862,\n",
       "   0.61915,\n",
       "   0.61915,\n",
       "   0.61892,\n",
       "   0.62107,\n",
       "   0.62051,\n",
       "   0.61984,\n",
       "   0.61918,\n",
       "   0.61931,\n",
       "   0.61934,\n",
       "   0.62024,\n",
       "   0.61959,\n",
       "   0.62038,\n",
       "   0.61874,\n",
       "   0.61809,\n",
       "   0.61794,\n",
       "   0.61718,\n",
       "   0.61609,\n",
       "   0.6157,\n",
       "   0.61634,\n",
       "   0.61725,\n",
       "   0.61601,\n",
       "   0.61648,\n",
       "   0.61677,\n",
       "   0.61659,\n",
       "   0.61584,\n",
       "   0.61552,\n",
       "   0.61489,\n",
       "   0.61592,\n",
       "   0.61515,\n",
       "   0.61615,\n",
       "   0.61524,\n",
       "   0.61516,\n",
       "   0.61478,\n",
       "   0.61618,\n",
       "   0.61583,\n",
       "   0.61515,\n",
       "   0.61597,\n",
       "   0.61589,\n",
       "   0.61534,\n",
       "   0.61576,\n",
       "   0.61593,\n",
       "   0.61629,\n",
       "   0.6164,\n",
       "   0.61585,\n",
       "   0.61509,\n",
       "   0.61527],\n",
       "  'metrics/mAP50-95(B)': [0.25034,\n",
       "   0.25518,\n",
       "   0.19409,\n",
       "   0.2367,\n",
       "   0.26183,\n",
       "   0.25533,\n",
       "   0.26232,\n",
       "   0.27419,\n",
       "   0.27539,\n",
       "   0.298,\n",
       "   0.29427,\n",
       "   0.29528,\n",
       "   0.30114,\n",
       "   0.29941,\n",
       "   0.30693,\n",
       "   0.30811,\n",
       "   0.31166,\n",
       "   0.31788,\n",
       "   0.31051,\n",
       "   0.31531,\n",
       "   0.3157,\n",
       "   0.32251,\n",
       "   0.32436,\n",
       "   0.33073,\n",
       "   0.32218,\n",
       "   0.32667,\n",
       "   0.32979,\n",
       "   0.32929,\n",
       "   0.33646,\n",
       "   0.34092,\n",
       "   0.3349,\n",
       "   0.33547,\n",
       "   0.33399,\n",
       "   0.3364,\n",
       "   0.33723,\n",
       "   0.34411,\n",
       "   0.34282,\n",
       "   0.34469,\n",
       "   0.34457,\n",
       "   0.34452,\n",
       "   0.34293,\n",
       "   0.34937,\n",
       "   0.35273,\n",
       "   0.34797,\n",
       "   0.34623,\n",
       "   0.34922,\n",
       "   0.34912,\n",
       "   0.34838,\n",
       "   0.34728,\n",
       "   0.35001,\n",
       "   0.3577,\n",
       "   0.35714,\n",
       "   0.35417,\n",
       "   0.35726,\n",
       "   0.35059,\n",
       "   0.35429,\n",
       "   0.35726,\n",
       "   0.35543,\n",
       "   0.35568,\n",
       "   0.35593,\n",
       "   0.35947,\n",
       "   0.36335,\n",
       "   0.3595,\n",
       "   0.35891,\n",
       "   0.36273,\n",
       "   0.36383,\n",
       "   0.36255,\n",
       "   0.36641,\n",
       "   0.3621,\n",
       "   0.36645,\n",
       "   0.36865,\n",
       "   0.36763,\n",
       "   0.3675,\n",
       "   0.36423,\n",
       "   0.36286,\n",
       "   0.36456,\n",
       "   0.36246,\n",
       "   0.3646,\n",
       "   0.36907,\n",
       "   0.36461,\n",
       "   0.36701,\n",
       "   0.37071,\n",
       "   0.36755,\n",
       "   0.36835,\n",
       "   0.36866,\n",
       "   0.36848,\n",
       "   0.37184,\n",
       "   0.37462,\n",
       "   0.37108,\n",
       "   0.37499,\n",
       "   0.37279,\n",
       "   0.37275,\n",
       "   0.37213,\n",
       "   0.3706,\n",
       "   0.37504,\n",
       "   0.37667,\n",
       "   0.3744,\n",
       "   0.3757,\n",
       "   0.37485,\n",
       "   0.37171,\n",
       "   0.37024,\n",
       "   0.37033,\n",
       "   0.37314,\n",
       "   0.37208,\n",
       "   0.37299,\n",
       "   0.37227,\n",
       "   0.37239,\n",
       "   0.37207,\n",
       "   0.37129,\n",
       "   0.36953,\n",
       "   0.37121,\n",
       "   0.37113,\n",
       "   0.37302,\n",
       "   0.37507,\n",
       "   0.37466,\n",
       "   0.37429,\n",
       "   0.37386,\n",
       "   0.37394,\n",
       "   0.37262,\n",
       "   0.37233,\n",
       "   0.37338,\n",
       "   0.37381,\n",
       "   0.37275,\n",
       "   0.37216,\n",
       "   0.37456,\n",
       "   0.37491,\n",
       "   0.37535,\n",
       "   0.37436,\n",
       "   0.37586,\n",
       "   0.37166,\n",
       "   0.37087,\n",
       "   0.37189,\n",
       "   0.37076,\n",
       "   0.37077,\n",
       "   0.37122,\n",
       "   0.37,\n",
       "   0.37044,\n",
       "   0.37044,\n",
       "   0.3705,\n",
       "   0.37035,\n",
       "   0.36973,\n",
       "   0.36949,\n",
       "   0.37004,\n",
       "   0.37057,\n",
       "   0.37019,\n",
       "   0.37122,\n",
       "   0.37185,\n",
       "   0.37201,\n",
       "   0.3732,\n",
       "   0.37132,\n",
       "   0.37188,\n",
       "   0.37198,\n",
       "   0.37187,\n",
       "   0.37158,\n",
       "   0.37147,\n",
       "   0.37152,\n",
       "   0.37122,\n",
       "   0.37097,\n",
       "   0.37037,\n",
       "   0.3704,\n",
       "   0.37036,\n",
       "   0.36985,\n",
       "   0.37002,\n",
       "   0.3688,\n",
       "   0.36876,\n",
       "   0.36917,\n",
       "   0.36914,\n",
       "   0.36922,\n",
       "   0.36952,\n",
       "   0.36907,\n",
       "   0.36934,\n",
       "   0.36902,\n",
       "   0.36939,\n",
       "   0.36899,\n",
       "   0.36881,\n",
       "   0.36849,\n",
       "   0.36878,\n",
       "   0.36908,\n",
       "   0.36923,\n",
       "   0.36902,\n",
       "   0.36829,\n",
       "   0.36897,\n",
       "   0.36856,\n",
       "   0.36839,\n",
       "   0.36819,\n",
       "   0.3677,\n",
       "   0.36823,\n",
       "   0.36724,\n",
       "   0.36758,\n",
       "   0.36748,\n",
       "   0.36792,\n",
       "   0.36803,\n",
       "   0.36754,\n",
       "   0.36763,\n",
       "   0.36691,\n",
       "   0.36643],\n",
       "  'val/box_loss': [1.64556,\n",
       "   1.64827,\n",
       "   1.79827,\n",
       "   1.70621,\n",
       "   1.59233,\n",
       "   1.60671,\n",
       "   1.60386,\n",
       "   1.52388,\n",
       "   1.56643,\n",
       "   1.48772,\n",
       "   1.49032,\n",
       "   1.5273,\n",
       "   1.5068,\n",
       "   1.50059,\n",
       "   1.45692,\n",
       "   1.49406,\n",
       "   1.45552,\n",
       "   1.44691,\n",
       "   1.45303,\n",
       "   1.45371,\n",
       "   1.42921,\n",
       "   1.44058,\n",
       "   1.43106,\n",
       "   1.40604,\n",
       "   1.43332,\n",
       "   1.40677,\n",
       "   1.37656,\n",
       "   1.39607,\n",
       "   1.40141,\n",
       "   1.35996,\n",
       "   1.39638,\n",
       "   1.39639,\n",
       "   1.42149,\n",
       "   1.38432,\n",
       "   1.37319,\n",
       "   1.37948,\n",
       "   1.37291,\n",
       "   1.36621,\n",
       "   1.37582,\n",
       "   1.34056,\n",
       "   1.32813,\n",
       "   1.36334,\n",
       "   1.35141,\n",
       "   1.36851,\n",
       "   1.35863,\n",
       "   1.35375,\n",
       "   1.3549,\n",
       "   1.32874,\n",
       "   1.34409,\n",
       "   1.34713,\n",
       "   1.33863,\n",
       "   1.32065,\n",
       "   1.32849,\n",
       "   1.34402,\n",
       "   1.34442,\n",
       "   1.32784,\n",
       "   1.32379,\n",
       "   1.33912,\n",
       "   1.34689,\n",
       "   1.33011,\n",
       "   1.33515,\n",
       "   1.32631,\n",
       "   1.31628,\n",
       "   1.32043,\n",
       "   1.31457,\n",
       "   1.318,\n",
       "   1.31427,\n",
       "   1.31488,\n",
       "   1.3197,\n",
       "   1.30629,\n",
       "   1.30163,\n",
       "   1.30604,\n",
       "   1.29801,\n",
       "   1.31978,\n",
       "   1.30423,\n",
       "   1.30356,\n",
       "   1.31233,\n",
       "   1.29754,\n",
       "   1.29538,\n",
       "   1.30819,\n",
       "   1.30397,\n",
       "   1.29834,\n",
       "   1.28324,\n",
       "   1.29087,\n",
       "   1.30441,\n",
       "   1.29873,\n",
       "   1.28473,\n",
       "   1.27398,\n",
       "   1.29907,\n",
       "   1.28166,\n",
       "   1.29004,\n",
       "   1.29721,\n",
       "   1.30467,\n",
       "   1.31228,\n",
       "   1.29633,\n",
       "   1.28536,\n",
       "   1.29649,\n",
       "   1.29583,\n",
       "   1.30291,\n",
       "   1.30189,\n",
       "   1.30052,\n",
       "   1.30733,\n",
       "   1.3085,\n",
       "   1.30718,\n",
       "   1.29652,\n",
       "   1.28839,\n",
       "   1.29355,\n",
       "   1.30009,\n",
       "   1.30563,\n",
       "   1.3056,\n",
       "   1.29785,\n",
       "   1.29302,\n",
       "   1.29013,\n",
       "   1.29487,\n",
       "   1.29951,\n",
       "   1.30515,\n",
       "   1.3046,\n",
       "   1.30279,\n",
       "   1.29709,\n",
       "   1.29529,\n",
       "   1.28701,\n",
       "   1.28552,\n",
       "   1.28561,\n",
       "   1.28809,\n",
       "   1.28519,\n",
       "   1.28625,\n",
       "   1.29056,\n",
       "   1.29244,\n",
       "   1.29177,\n",
       "   1.29576,\n",
       "   1.29703,\n",
       "   1.30434,\n",
       "   1.30773,\n",
       "   1.31152,\n",
       "   1.3111,\n",
       "   1.31219,\n",
       "   1.30985,\n",
       "   1.30829,\n",
       "   1.30715,\n",
       "   1.30875,\n",
       "   1.30733,\n",
       "   1.30641,\n",
       "   1.30464,\n",
       "   1.30507,\n",
       "   1.30908,\n",
       "   1.30952,\n",
       "   1.31191,\n",
       "   1.31274,\n",
       "   1.31305,\n",
       "   1.3149,\n",
       "   1.31547,\n",
       "   1.31589,\n",
       "   1.31625,\n",
       "   1.31541,\n",
       "   1.31284,\n",
       "   1.31169,\n",
       "   1.31121,\n",
       "   1.30962,\n",
       "   1.30794,\n",
       "   1.30854,\n",
       "   1.30673,\n",
       "   1.31034,\n",
       "   1.31149,\n",
       "   1.31448,\n",
       "   1.31523,\n",
       "   1.31508,\n",
       "   1.31472,\n",
       "   1.3142,\n",
       "   1.3158,\n",
       "   1.31577,\n",
       "   1.31635,\n",
       "   1.31812,\n",
       "   1.3186,\n",
       "   1.31883,\n",
       "   1.31963,\n",
       "   1.31917,\n",
       "   1.31902,\n",
       "   1.31885,\n",
       "   1.31782,\n",
       "   1.319,\n",
       "   1.31963,\n",
       "   1.31916,\n",
       "   1.321,\n",
       "   1.32213,\n",
       "   1.32155,\n",
       "   1.32227,\n",
       "   1.32152,\n",
       "   1.32217,\n",
       "   1.32194,\n",
       "   1.32282,\n",
       "   1.3235,\n",
       "   1.32364,\n",
       "   1.32402,\n",
       "   1.32461,\n",
       "   1.32614,\n",
       "   1.32599],\n",
       "  'val/cls_loss': [1.40684,\n",
       "   1.33172,\n",
       "   1.44406,\n",
       "   1.30972,\n",
       "   1.26372,\n",
       "   1.2529,\n",
       "   1.2236,\n",
       "   1.1525,\n",
       "   1.17656,\n",
       "   1.07367,\n",
       "   1.12853,\n",
       "   1.06726,\n",
       "   1.07455,\n",
       "   1.07683,\n",
       "   1.0745,\n",
       "   1.06142,\n",
       "   1.02969,\n",
       "   1.03591,\n",
       "   1.03222,\n",
       "   1.05205,\n",
       "   1.03447,\n",
       "   1.0103,\n",
       "   1.02222,\n",
       "   0.99832,\n",
       "   1.01035,\n",
       "   1.00599,\n",
       "   1.02138,\n",
       "   0.97287,\n",
       "   0.99959,\n",
       "   0.94565,\n",
       "   0.96916,\n",
       "   0.98856,\n",
       "   0.98802,\n",
       "   0.94623,\n",
       "   0.95818,\n",
       "   0.94644,\n",
       "   0.95508,\n",
       "   0.95117,\n",
       "   0.9422,\n",
       "   0.92815,\n",
       "   0.95913,\n",
       "   0.9282,\n",
       "   0.91857,\n",
       "   0.96474,\n",
       "   0.9185,\n",
       "   0.92449,\n",
       "   0.90811,\n",
       "   0.93187,\n",
       "   0.92145,\n",
       "   0.91549,\n",
       "   0.89514,\n",
       "   0.90507,\n",
       "   0.89595,\n",
       "   0.8898,\n",
       "   0.912,\n",
       "   0.89145,\n",
       "   0.89728,\n",
       "   0.91228,\n",
       "   0.90499,\n",
       "   0.88422,\n",
       "   0.90561,\n",
       "   0.88566,\n",
       "   0.88914,\n",
       "   0.91056,\n",
       "   0.8932,\n",
       "   0.89058,\n",
       "   0.89504,\n",
       "   0.87737,\n",
       "   0.88414,\n",
       "   0.88114,\n",
       "   0.86937,\n",
       "   0.86421,\n",
       "   0.86828,\n",
       "   0.88225,\n",
       "   0.88358,\n",
       "   0.86959,\n",
       "   0.87297,\n",
       "   0.8714,\n",
       "   0.86261,\n",
       "   0.85766,\n",
       "   0.87893,\n",
       "   0.86304,\n",
       "   0.86436,\n",
       "   0.86948,\n",
       "   0.89265,\n",
       "   0.86262,\n",
       "   0.85944,\n",
       "   0.84713,\n",
       "   0.85477,\n",
       "   0.84912,\n",
       "   0.83333,\n",
       "   0.85493,\n",
       "   0.85463,\n",
       "   0.85162,\n",
       "   0.84803,\n",
       "   0.843,\n",
       "   0.85452,\n",
       "   0.85828,\n",
       "   0.85576,\n",
       "   0.84964,\n",
       "   0.84693,\n",
       "   0.85237,\n",
       "   0.85637,\n",
       "   0.85103,\n",
       "   0.84738,\n",
       "   0.84802,\n",
       "   0.84467,\n",
       "   0.84904,\n",
       "   0.84967,\n",
       "   0.85354,\n",
       "   0.8555,\n",
       "   0.8535,\n",
       "   0.85318,\n",
       "   0.84967,\n",
       "   0.85041,\n",
       "   0.84423,\n",
       "   0.84273,\n",
       "   0.84233,\n",
       "   0.84327,\n",
       "   0.83829,\n",
       "   0.83976,\n",
       "   0.83509,\n",
       "   0.83744,\n",
       "   0.83992,\n",
       "   0.84246,\n",
       "   0.83832,\n",
       "   0.84296,\n",
       "   0.84254,\n",
       "   0.83809,\n",
       "   0.83588,\n",
       "   0.83804,\n",
       "   0.83993,\n",
       "   0.84688,\n",
       "   0.85116,\n",
       "   0.85166,\n",
       "   0.85152,\n",
       "   0.85394,\n",
       "   0.85077,\n",
       "   0.85072,\n",
       "   0.85448,\n",
       "   0.85188,\n",
       "   0.85005,\n",
       "   0.84707,\n",
       "   0.84835,\n",
       "   0.84873,\n",
       "   0.84869,\n",
       "   0.85156,\n",
       "   0.85222,\n",
       "   0.85414,\n",
       "   0.85567,\n",
       "   0.8538,\n",
       "   0.85218,\n",
       "   0.85056,\n",
       "   0.8514,\n",
       "   0.84981,\n",
       "   0.84842,\n",
       "   0.85098,\n",
       "   0.84965,\n",
       "   0.85123,\n",
       "   0.85445,\n",
       "   0.85341,\n",
       "   0.8558,\n",
       "   0.85384,\n",
       "   0.85333,\n",
       "   0.85398,\n",
       "   0.8554,\n",
       "   0.85475,\n",
       "   0.85337,\n",
       "   0.85568,\n",
       "   0.85359,\n",
       "   0.85503,\n",
       "   0.85674,\n",
       "   0.85491,\n",
       "   0.85543,\n",
       "   0.85439,\n",
       "   0.85656,\n",
       "   0.8566,\n",
       "   0.85745,\n",
       "   0.85788,\n",
       "   0.86151,\n",
       "   0.86402,\n",
       "   0.86395,\n",
       "   0.86679,\n",
       "   0.86756,\n",
       "   0.86714,\n",
       "   0.86869,\n",
       "   0.86894,\n",
       "   0.86917,\n",
       "   0.87061,\n",
       "   0.8687,\n",
       "   0.86931,\n",
       "   0.86936,\n",
       "   0.86849,\n",
       "   0.86911,\n",
       "   0.87245,\n",
       "   0.87006],\n",
       "  'val/dfl_loss': [1.0391,\n",
       "   1.03986,\n",
       "   1.09908,\n",
       "   1.06286,\n",
       "   1.06087,\n",
       "   1.05106,\n",
       "   1.05472,\n",
       "   1.02521,\n",
       "   1.04392,\n",
       "   1.01412,\n",
       "   1.01764,\n",
       "   1.02248,\n",
       "   1.01754,\n",
       "   1.01133,\n",
       "   1.00937,\n",
       "   1.02219,\n",
       "   0.99903,\n",
       "   0.99771,\n",
       "   1.00343,\n",
       "   1.00071,\n",
       "   1.00062,\n",
       "   1.00115,\n",
       "   0.99566,\n",
       "   0.9935,\n",
       "   0.99391,\n",
       "   0.98805,\n",
       "   0.97441,\n",
       "   0.98401,\n",
       "   0.98946,\n",
       "   0.96895,\n",
       "   0.99159,\n",
       "   0.98379,\n",
       "   0.99623,\n",
       "   0.98093,\n",
       "   0.97788,\n",
       "   0.97297,\n",
       "   0.9804,\n",
       "   0.98043,\n",
       "   0.97907,\n",
       "   0.96931,\n",
       "   0.96269,\n",
       "   0.97212,\n",
       "   0.96883,\n",
       "   0.97767,\n",
       "   0.97282,\n",
       "   0.96981,\n",
       "   0.96769,\n",
       "   0.95979,\n",
       "   0.96367,\n",
       "   0.96257,\n",
       "   0.95988,\n",
       "   0.95778,\n",
       "   0.95704,\n",
       "   0.9652,\n",
       "   0.96566,\n",
       "   0.96306,\n",
       "   0.95473,\n",
       "   0.96167,\n",
       "   0.96765,\n",
       "   0.95531,\n",
       "   0.96643,\n",
       "   0.95831,\n",
       "   0.95146,\n",
       "   0.96149,\n",
       "   0.95907,\n",
       "   0.95553,\n",
       "   0.95528,\n",
       "   0.95857,\n",
       "   0.95788,\n",
       "   0.95156,\n",
       "   0.95058,\n",
       "   0.95679,\n",
       "   0.95217,\n",
       "   0.95822,\n",
       "   0.95725,\n",
       "   0.95303,\n",
       "   0.95617,\n",
       "   0.95052,\n",
       "   0.94942,\n",
       "   0.95112,\n",
       "   0.95019,\n",
       "   0.94892,\n",
       "   0.94625,\n",
       "   0.94991,\n",
       "   0.95609,\n",
       "   0.94851,\n",
       "   0.94713,\n",
       "   0.94623,\n",
       "   0.94965,\n",
       "   0.94403,\n",
       "   0.94522,\n",
       "   0.94726,\n",
       "   0.95102,\n",
       "   0.95661,\n",
       "   0.95112,\n",
       "   0.94951,\n",
       "   0.95107,\n",
       "   0.94967,\n",
       "   0.95008,\n",
       "   0.94925,\n",
       "   0.95015,\n",
       "   0.95369,\n",
       "   0.95117,\n",
       "   0.95218,\n",
       "   0.94563,\n",
       "   0.94559,\n",
       "   0.94813,\n",
       "   0.94813,\n",
       "   0.94954,\n",
       "   0.95024,\n",
       "   0.94838,\n",
       "   0.94709,\n",
       "   0.94716,\n",
       "   0.94822,\n",
       "   0.94793,\n",
       "   0.94924,\n",
       "   0.94809,\n",
       "   0.94678,\n",
       "   0.94458,\n",
       "   0.94213,\n",
       "   0.94067,\n",
       "   0.9414,\n",
       "   0.94145,\n",
       "   0.94157,\n",
       "   0.94078,\n",
       "   0.941,\n",
       "   0.94137,\n",
       "   0.94295,\n",
       "   0.94349,\n",
       "   0.94431,\n",
       "   0.94475,\n",
       "   0.94715,\n",
       "   0.94813,\n",
       "   0.9492,\n",
       "   0.95027,\n",
       "   0.95031,\n",
       "   0.94982,\n",
       "   0.94763,\n",
       "   0.94768,\n",
       "   0.94778,\n",
       "   0.94655,\n",
       "   0.94619,\n",
       "   0.94548,\n",
       "   0.94537,\n",
       "   0.94654,\n",
       "   0.9467,\n",
       "   0.94736,\n",
       "   0.94804,\n",
       "   0.94803,\n",
       "   0.94882,\n",
       "   0.9486,\n",
       "   0.94914,\n",
       "   0.94967,\n",
       "   0.94991,\n",
       "   0.94927,\n",
       "   0.94885,\n",
       "   0.94809,\n",
       "   0.94792,\n",
       "   0.94797,\n",
       "   0.94861,\n",
       "   0.94806,\n",
       "   0.94851,\n",
       "   0.94873,\n",
       "   0.94911,\n",
       "   0.94955,\n",
       "   0.94953,\n",
       "   0.94973,\n",
       "   0.94962,\n",
       "   0.95016,\n",
       "   0.95035,\n",
       "   0.95021,\n",
       "   0.95045,\n",
       "   0.9504,\n",
       "   0.95053,\n",
       "   0.95034,\n",
       "   0.95032,\n",
       "   0.95034,\n",
       "   0.95036,\n",
       "   0.95006,\n",
       "   0.95019,\n",
       "   0.95023,\n",
       "   0.95026,\n",
       "   0.95044,\n",
       "   0.95098,\n",
       "   0.95092,\n",
       "   0.95116,\n",
       "   0.95111,\n",
       "   0.95131,\n",
       "   0.95152,\n",
       "   0.95138,\n",
       "   0.9516,\n",
       "   0.95192,\n",
       "   0.9523,\n",
       "   0.95237,\n",
       "   0.9526,\n",
       "   0.95292],\n",
       "  'lr/pg0': [0.00332378,\n",
       "   0.00662416,\n",
       "   0.00989154,\n",
       "   0.0098515,\n",
       "   0.009802,\n",
       "   0.0097525,\n",
       "   0.009703,\n",
       "   0.0096535,\n",
       "   0.009604,\n",
       "   0.0095545,\n",
       "   0.009505,\n",
       "   0.0094555,\n",
       "   0.009406,\n",
       "   0.0093565,\n",
       "   0.009307,\n",
       "   0.0092575,\n",
       "   0.009208,\n",
       "   0.0091585,\n",
       "   0.009109,\n",
       "   0.0090595,\n",
       "   0.00901,\n",
       "   0.0089605,\n",
       "   0.008911,\n",
       "   0.0088615,\n",
       "   0.008812,\n",
       "   0.0087625,\n",
       "   0.008713,\n",
       "   0.0086635,\n",
       "   0.008614,\n",
       "   0.0085645,\n",
       "   0.008515,\n",
       "   0.0084655,\n",
       "   0.008416,\n",
       "   0.0083665,\n",
       "   0.008317,\n",
       "   0.0082675,\n",
       "   0.008218,\n",
       "   0.0081685,\n",
       "   0.008119,\n",
       "   0.0080695,\n",
       "   0.00802,\n",
       "   0.0079705,\n",
       "   0.007921,\n",
       "   0.0078715,\n",
       "   0.007822,\n",
       "   0.0077725,\n",
       "   0.007723,\n",
       "   0.0076735,\n",
       "   0.007624,\n",
       "   0.0075745,\n",
       "   0.007525,\n",
       "   0.0074755,\n",
       "   0.007426,\n",
       "   0.0073765,\n",
       "   0.007327,\n",
       "   0.0072775,\n",
       "   0.007228,\n",
       "   0.0071785,\n",
       "   0.007129,\n",
       "   0.0070795,\n",
       "   0.00703,\n",
       "   0.0069805,\n",
       "   0.006931,\n",
       "   0.0068815,\n",
       "   0.006832,\n",
       "   0.0067825,\n",
       "   0.006733,\n",
       "   0.0066835,\n",
       "   0.006634,\n",
       "   0.0065845,\n",
       "   0.006535,\n",
       "   0.0064855,\n",
       "   0.006436,\n",
       "   0.0063865,\n",
       "   0.006337,\n",
       "   0.0062875,\n",
       "   0.006238,\n",
       "   0.0061885,\n",
       "   0.006139,\n",
       "   0.0060895,\n",
       "   0.00604,\n",
       "   0.0059905,\n",
       "   0.005941,\n",
       "   0.0058915,\n",
       "   0.005842,\n",
       "   0.0057925,\n",
       "   0.005743,\n",
       "   0.0056935,\n",
       "   0.005644,\n",
       "   0.0055945,\n",
       "   0.005545,\n",
       "   0.0054955,\n",
       "   0.005446,\n",
       "   0.0053965,\n",
       "   0.005347,\n",
       "   0.0052975,\n",
       "   0.005248,\n",
       "   0.0051985,\n",
       "   0.005149,\n",
       "   0.0050995,\n",
       "   0.00505,\n",
       "   0.0050005,\n",
       "   0.004951,\n",
       "   0.0049015,\n",
       "   0.004852,\n",
       "   0.0048025,\n",
       "   0.004753,\n",
       "   0.0047035,\n",
       "   0.004654,\n",
       "   0.0046045,\n",
       "   0.004555,\n",
       "   0.0045055,\n",
       "   0.004456,\n",
       "   0.0044065,\n",
       "   0.004357,\n",
       "   0.0043075,\n",
       "   0.004258,\n",
       "   0.0042085,\n",
       "   0.004159,\n",
       "   0.0041095,\n",
       "   0.00406,\n",
       "   0.0040105,\n",
       "   0.003961,\n",
       "   0.0039115,\n",
       "   0.003862,\n",
       "   0.0038125,\n",
       "   0.003763,\n",
       "   0.0037135,\n",
       "   0.003664,\n",
       "   0.0036145,\n",
       "   0.003565,\n",
       "   0.0035155,\n",
       "   0.003466,\n",
       "   0.0034165,\n",
       "   0.003367,\n",
       "   0.0033175,\n",
       "   0.003268,\n",
       "   0.0032185,\n",
       "   0.003169,\n",
       "   0.0031195,\n",
       "   0.00307,\n",
       "   0.0030205,\n",
       "   0.002971,\n",
       "   0.0029215,\n",
       "   0.002872,\n",
       "   0.0028225,\n",
       "   0.002773,\n",
       "   0.0027235,\n",
       "   0.002674,\n",
       "   0.0026245,\n",
       "   0.002575,\n",
       "   0.0025255,\n",
       "   0.002476,\n",
       "   0.0024265,\n",
       "   0.002377,\n",
       "   0.0023275,\n",
       "   0.002278,\n",
       "   0.0022285,\n",
       "   0.002179,\n",
       "   0.0021295,\n",
       "   0.00208,\n",
       "   0.0020305,\n",
       "   0.001981,\n",
       "   0.0019315,\n",
       "   0.001882,\n",
       "   0.0018325,\n",
       "   0.001783,\n",
       "   0.0017335,\n",
       "   0.001684,\n",
       "   0.0016345,\n",
       "   0.001585,\n",
       "   0.0015355,\n",
       "   0.001486,\n",
       "   0.0014365,\n",
       "   0.001387,\n",
       "   0.0013375,\n",
       "   0.001288,\n",
       "   0.0012385,\n",
       "   0.001189,\n",
       "   0.0011395,\n",
       "   0.00109,\n",
       "   0.0010405,\n",
       "   0.000991,\n",
       "   0.0009415,\n",
       "   0.000892,\n",
       "   0.0008425,\n",
       "   0.000793,\n",
       "   0.0007435,\n",
       "   0.000694,\n",
       "   0.0006445,\n",
       "   0.000595,\n",
       "   0.0005455,\n",
       "   0.000496,\n",
       "   0.0004465,\n",
       "   0.000397,\n",
       "   0.0003475],\n",
       "  'lr/pg1': [0.00332378,\n",
       "   0.00662416,\n",
       "   0.00989154,\n",
       "   0.0098515,\n",
       "   0.009802,\n",
       "   0.0097525,\n",
       "   0.009703,\n",
       "   0.0096535,\n",
       "   0.009604,\n",
       "   0.0095545,\n",
       "   0.009505,\n",
       "   0.0094555,\n",
       "   0.009406,\n",
       "   0.0093565,\n",
       "   0.009307,\n",
       "   0.0092575,\n",
       "   0.009208,\n",
       "   0.0091585,\n",
       "   0.009109,\n",
       "   0.0090595,\n",
       "   0.00901,\n",
       "   0.0089605,\n",
       "   0.008911,\n",
       "   0.0088615,\n",
       "   0.008812,\n",
       "   0.0087625,\n",
       "   0.008713,\n",
       "   0.0086635,\n",
       "   0.008614,\n",
       "   0.0085645,\n",
       "   0.008515,\n",
       "   0.0084655,\n",
       "   0.008416,\n",
       "   0.0083665,\n",
       "   0.008317,\n",
       "   0.0082675,\n",
       "   0.008218,\n",
       "   0.0081685,\n",
       "   0.008119,\n",
       "   0.0080695,\n",
       "   0.00802,\n",
       "   0.0079705,\n",
       "   0.007921,\n",
       "   0.0078715,\n",
       "   0.007822,\n",
       "   0.0077725,\n",
       "   0.007723,\n",
       "   0.0076735,\n",
       "   0.007624,\n",
       "   0.0075745,\n",
       "   0.007525,\n",
       "   0.0074755,\n",
       "   0.007426,\n",
       "   0.0073765,\n",
       "   0.007327,\n",
       "   0.0072775,\n",
       "   0.007228,\n",
       "   0.0071785,\n",
       "   0.007129,\n",
       "   0.0070795,\n",
       "   0.00703,\n",
       "   0.0069805,\n",
       "   0.006931,\n",
       "   0.0068815,\n",
       "   0.006832,\n",
       "   0.0067825,\n",
       "   0.006733,\n",
       "   0.0066835,\n",
       "   0.006634,\n",
       "   0.0065845,\n",
       "   0.006535,\n",
       "   0.0064855,\n",
       "   0.006436,\n",
       "   0.0063865,\n",
       "   0.006337,\n",
       "   0.0062875,\n",
       "   0.006238,\n",
       "   0.0061885,\n",
       "   0.006139,\n",
       "   0.0060895,\n",
       "   0.00604,\n",
       "   0.0059905,\n",
       "   0.005941,\n",
       "   0.0058915,\n",
       "   0.005842,\n",
       "   0.0057925,\n",
       "   0.005743,\n",
       "   0.0056935,\n",
       "   0.005644,\n",
       "   0.0055945,\n",
       "   0.005545,\n",
       "   0.0054955,\n",
       "   0.005446,\n",
       "   0.0053965,\n",
       "   0.005347,\n",
       "   0.0052975,\n",
       "   0.005248,\n",
       "   0.0051985,\n",
       "   0.005149,\n",
       "   0.0050995,\n",
       "   0.00505,\n",
       "   0.0050005,\n",
       "   0.004951,\n",
       "   0.0049015,\n",
       "   0.004852,\n",
       "   0.0048025,\n",
       "   0.004753,\n",
       "   0.0047035,\n",
       "   0.004654,\n",
       "   0.0046045,\n",
       "   0.004555,\n",
       "   0.0045055,\n",
       "   0.004456,\n",
       "   0.0044065,\n",
       "   0.004357,\n",
       "   0.0043075,\n",
       "   0.004258,\n",
       "   0.0042085,\n",
       "   0.004159,\n",
       "   0.0041095,\n",
       "   0.00406,\n",
       "   0.0040105,\n",
       "   0.003961,\n",
       "   0.0039115,\n",
       "   0.003862,\n",
       "   0.0038125,\n",
       "   0.003763,\n",
       "   0.0037135,\n",
       "   0.003664,\n",
       "   0.0036145,\n",
       "   0.003565,\n",
       "   0.0035155,\n",
       "   0.003466,\n",
       "   0.0034165,\n",
       "   0.003367,\n",
       "   0.0033175,\n",
       "   0.003268,\n",
       "   0.0032185,\n",
       "   0.003169,\n",
       "   0.0031195,\n",
       "   0.00307,\n",
       "   0.0030205,\n",
       "   0.002971,\n",
       "   0.0029215,\n",
       "   0.002872,\n",
       "   0.0028225,\n",
       "   0.002773,\n",
       "   0.0027235,\n",
       "   0.002674,\n",
       "   0.0026245,\n",
       "   0.002575,\n",
       "   0.0025255,\n",
       "   0.002476,\n",
       "   0.0024265,\n",
       "   0.002377,\n",
       "   0.0023275,\n",
       "   0.002278,\n",
       "   0.0022285,\n",
       "   0.002179,\n",
       "   0.0021295,\n",
       "   0.00208,\n",
       "   0.0020305,\n",
       "   0.001981,\n",
       "   0.0019315,\n",
       "   0.001882,\n",
       "   0.0018325,\n",
       "   0.001783,\n",
       "   0.0017335,\n",
       "   0.001684,\n",
       "   0.0016345,\n",
       "   0.001585,\n",
       "   0.0015355,\n",
       "   0.001486,\n",
       "   0.0014365,\n",
       "   0.001387,\n",
       "   0.0013375,\n",
       "   0.001288,\n",
       "   0.0012385,\n",
       "   0.001189,\n",
       "   0.0011395,\n",
       "   0.00109,\n",
       "   0.0010405,\n",
       "   0.000991,\n",
       "   0.0009415,\n",
       "   0.000892,\n",
       "   0.0008425,\n",
       "   0.000793,\n",
       "   0.0007435,\n",
       "   0.000694,\n",
       "   0.0006445,\n",
       "   0.000595,\n",
       "   0.0005455,\n",
       "   0.000496,\n",
       "   0.0004465,\n",
       "   0.000397,\n",
       "   0.0003475],\n",
       "  'lr/pg2': [0.00332378,\n",
       "   0.00662416,\n",
       "   0.00989154,\n",
       "   0.0098515,\n",
       "   0.009802,\n",
       "   0.0097525,\n",
       "   0.009703,\n",
       "   0.0096535,\n",
       "   0.009604,\n",
       "   0.0095545,\n",
       "   0.009505,\n",
       "   0.0094555,\n",
       "   0.009406,\n",
       "   0.0093565,\n",
       "   0.009307,\n",
       "   0.0092575,\n",
       "   0.009208,\n",
       "   0.0091585,\n",
       "   0.009109,\n",
       "   0.0090595,\n",
       "   0.00901,\n",
       "   0.0089605,\n",
       "   0.008911,\n",
       "   0.0088615,\n",
       "   0.008812,\n",
       "   0.0087625,\n",
       "   0.008713,\n",
       "   0.0086635,\n",
       "   0.008614,\n",
       "   0.0085645,\n",
       "   0.008515,\n",
       "   0.0084655,\n",
       "   0.008416,\n",
       "   0.0083665,\n",
       "   0.008317,\n",
       "   0.0082675,\n",
       "   0.008218,\n",
       "   0.0081685,\n",
       "   0.008119,\n",
       "   0.0080695,\n",
       "   0.00802,\n",
       "   0.0079705,\n",
       "   0.007921,\n",
       "   0.0078715,\n",
       "   0.007822,\n",
       "   0.0077725,\n",
       "   0.007723,\n",
       "   0.0076735,\n",
       "   0.007624,\n",
       "   0.0075745,\n",
       "   0.007525,\n",
       "   0.0074755,\n",
       "   0.007426,\n",
       "   0.0073765,\n",
       "   0.007327,\n",
       "   0.0072775,\n",
       "   0.007228,\n",
       "   0.0071785,\n",
       "   0.007129,\n",
       "   0.0070795,\n",
       "   0.00703,\n",
       "   0.0069805,\n",
       "   0.006931,\n",
       "   0.0068815,\n",
       "   0.006832,\n",
       "   0.0067825,\n",
       "   0.006733,\n",
       "   0.0066835,\n",
       "   0.006634,\n",
       "   0.0065845,\n",
       "   0.006535,\n",
       "   0.0064855,\n",
       "   0.006436,\n",
       "   0.0063865,\n",
       "   0.006337,\n",
       "   0.0062875,\n",
       "   0.006238,\n",
       "   0.0061885,\n",
       "   0.006139,\n",
       "   0.0060895,\n",
       "   0.00604,\n",
       "   0.0059905,\n",
       "   0.005941,\n",
       "   0.0058915,\n",
       "   0.005842,\n",
       "   0.0057925,\n",
       "   0.005743,\n",
       "   0.0056935,\n",
       "   0.005644,\n",
       "   0.0055945,\n",
       "   0.005545,\n",
       "   0.0054955,\n",
       "   0.005446,\n",
       "   0.0053965,\n",
       "   0.005347,\n",
       "   0.0052975,\n",
       "   0.005248,\n",
       "   0.0051985,\n",
       "   0.005149,\n",
       "   0.0050995,\n",
       "   0.00505,\n",
       "   0.0050005,\n",
       "   0.004951,\n",
       "   0.0049015,\n",
       "   0.004852,\n",
       "   0.0048025,\n",
       "   0.004753,\n",
       "   0.0047035,\n",
       "   0.004654,\n",
       "   0.0046045,\n",
       "   0.004555,\n",
       "   0.0045055,\n",
       "   0.004456,\n",
       "   0.0044065,\n",
       "   0.004357,\n",
       "   0.0043075,\n",
       "   0.004258,\n",
       "   0.0042085,\n",
       "   0.004159,\n",
       "   0.0041095,\n",
       "   0.00406,\n",
       "   0.0040105,\n",
       "   0.003961,\n",
       "   0.0039115,\n",
       "   0.003862,\n",
       "   0.0038125,\n",
       "   0.003763,\n",
       "   0.0037135,\n",
       "   0.003664,\n",
       "   0.0036145,\n",
       "   0.003565,\n",
       "   0.0035155,\n",
       "   0.003466,\n",
       "   0.0034165,\n",
       "   0.003367,\n",
       "   0.0033175,\n",
       "   0.003268,\n",
       "   0.0032185,\n",
       "   0.003169,\n",
       "   0.0031195,\n",
       "   0.00307,\n",
       "   0.0030205,\n",
       "   0.002971,\n",
       "   0.0029215,\n",
       "   0.002872,\n",
       "   0.0028225,\n",
       "   0.002773,\n",
       "   0.0027235,\n",
       "   0.002674,\n",
       "   0.0026245,\n",
       "   0.002575,\n",
       "   0.0025255,\n",
       "   0.002476,\n",
       "   0.0024265,\n",
       "   0.002377,\n",
       "   0.0023275,\n",
       "   0.002278,\n",
       "   0.0022285,\n",
       "   0.002179,\n",
       "   0.0021295,\n",
       "   0.00208,\n",
       "   0.0020305,\n",
       "   0.001981,\n",
       "   0.0019315,\n",
       "   0.001882,\n",
       "   0.0018325,\n",
       "   0.001783,\n",
       "   0.0017335,\n",
       "   0.001684,\n",
       "   0.0016345,\n",
       "   0.001585,\n",
       "   0.0015355,\n",
       "   0.001486,\n",
       "   0.0014365,\n",
       "   0.001387,\n",
       "   0.0013375,\n",
       "   0.001288,\n",
       "   0.0012385,\n",
       "   0.001189,\n",
       "   0.0011395,\n",
       "   0.00109,\n",
       "   0.0010405,\n",
       "   0.000991,\n",
       "   0.0009415,\n",
       "   0.000892,\n",
       "   0.0008425,\n",
       "   0.000793,\n",
       "   0.0007435,\n",
       "   0.000694,\n",
       "   0.0006445,\n",
       "   0.000595,\n",
       "   0.0005455,\n",
       "   0.000496,\n",
       "   0.0004465,\n",
       "   0.000397,\n",
       "   0.0003475]}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(INPUT_PATH)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsity(model):\n",
    "    '''Return global model sparsity'''\n",
    "    a = 0\n",
    "    b = 0\n",
    "\n",
    "    for p in model.parameters():\n",
    "        a += p.numel()\n",
    "        b += (p == 0).sum()\n",
    "\n",
    "    return b / a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pruned to 0.299 global sparsity\n"
     ]
    }
   ],
   "source": [
    "pruning_param = 0.3\n",
    "\n",
    "for name, m in model['model'].named_modules():\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "        prune.l1_unstructured(m, name='weight', amount=pruning_param)  # prune\n",
    "        prune.remove(m, 'weight')\n",
    "\n",
    "print(f'Model pruned to {sparsity(model['model']):.3g} global sparsity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2024-12-11T09:39:49.714782',\n",
       " 'version': '8.3.49',\n",
       " 'license': 'AGPL-3.0 (https://ultralytics.com/license)',\n",
       " 'docs': 'https://docs.ultralytics.com',\n",
       " 'epoch': -1,\n",
       " 'best_fitness': None,\n",
       " 'model': DetectionModel(\n",
       "   (model): Sequential(\n",
       "     (0): Conv(\n",
       "       (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (1): Conv(\n",
       "       (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (2): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (3): Conv(\n",
       "       (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (4): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (5): Conv(\n",
       "       (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (6): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (7): Conv(\n",
       "       (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (8): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (9): SPPF(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "     (10): Upsample(scale_factor=2.0, mode='nearest')\n",
       "     (11): Concat()\n",
       "     (12): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (13): Upsample(scale_factor=2.0, mode='nearest')\n",
       "     (14): Concat()\n",
       "     (15): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (16): Conv(\n",
       "       (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (17): Concat()\n",
       "     (18): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (19): Conv(\n",
       "       (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (20): Concat()\n",
       "     (21): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (22): Detect(\n",
       "       (cv2): ModuleList(\n",
       "         (0): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (1): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (2): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (cv3): ModuleList(\n",
       "         (0): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (1): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (2): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (dfl): DFL(\n",
       "         (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'ema': None,\n",
       " 'updates': None,\n",
       " 'optimizer': None,\n",
       " 'train_args': {'task': 'detect',\n",
       "  'mode': 'train',\n",
       "  'model': 'yolov8n.pt',\n",
       "  'data': '/kaggle/input/cityperson/data.yaml',\n",
       "  'epochs': 200,\n",
       "  'time': None,\n",
       "  'patience': 100,\n",
       "  'batch': 16,\n",
       "  'imgsz': 640,\n",
       "  'save': True,\n",
       "  'save_period': -1,\n",
       "  'cache': False,\n",
       "  'device': 0,\n",
       "  'workers': 8,\n",
       "  'project': None,\n",
       "  'name': 'train',\n",
       "  'exist_ok': False,\n",
       "  'pretrained': True,\n",
       "  'optimizer': 'auto',\n",
       "  'verbose': True,\n",
       "  'seed': 0,\n",
       "  'deterministic': True,\n",
       "  'single_cls': False,\n",
       "  'rect': False,\n",
       "  'cos_lr': False,\n",
       "  'close_mosaic': 10,\n",
       "  'resume': False,\n",
       "  'amp': True,\n",
       "  'fraction': 1.0,\n",
       "  'profile': False,\n",
       "  'freeze': None,\n",
       "  'multi_scale': False,\n",
       "  'overlap_mask': True,\n",
       "  'mask_ratio': 4,\n",
       "  'dropout': 0.0,\n",
       "  'val': True,\n",
       "  'split': 'val',\n",
       "  'save_json': False,\n",
       "  'save_hybrid': False,\n",
       "  'conf': None,\n",
       "  'iou': 0.7,\n",
       "  'max_det': 300,\n",
       "  'half': False,\n",
       "  'dnn': False,\n",
       "  'plots': True,\n",
       "  'source': None,\n",
       "  'vid_stride': 1,\n",
       "  'stream_buffer': False,\n",
       "  'visualize': False,\n",
       "  'augment': False,\n",
       "  'agnostic_nms': False,\n",
       "  'classes': None,\n",
       "  'retina_masks': False,\n",
       "  'embed': None,\n",
       "  'show': False,\n",
       "  'save_frames': False,\n",
       "  'save_txt': False,\n",
       "  'save_conf': False,\n",
       "  'save_crop': False,\n",
       "  'show_labels': True,\n",
       "  'show_conf': True,\n",
       "  'show_boxes': True,\n",
       "  'line_width': None,\n",
       "  'format': 'torchscript',\n",
       "  'keras': False,\n",
       "  'optimize': False,\n",
       "  'int8': False,\n",
       "  'dynamic': False,\n",
       "  'simplify': True,\n",
       "  'opset': None,\n",
       "  'workspace': None,\n",
       "  'nms': False,\n",
       "  'lr0': 0.01,\n",
       "  'lrf': 0.01,\n",
       "  'momentum': 0.937,\n",
       "  'weight_decay': 0.0005,\n",
       "  'warmup_epochs': 3.0,\n",
       "  'warmup_momentum': 0.8,\n",
       "  'warmup_bias_lr': 0.0,\n",
       "  'box': 7.5,\n",
       "  'cls': 0.5,\n",
       "  'dfl': 1.5,\n",
       "  'pose': 12.0,\n",
       "  'kobj': 1.0,\n",
       "  'nbs': 64,\n",
       "  'hsv_h': 0.015,\n",
       "  'hsv_s': 0.7,\n",
       "  'hsv_v': 0.4,\n",
       "  'degrees': 0.0,\n",
       "  'translate': 0.1,\n",
       "  'scale': 0.5,\n",
       "  'shear': 0.0,\n",
       "  'perspective': 0.0,\n",
       "  'flipud': 0.0,\n",
       "  'fliplr': 0.5,\n",
       "  'bgr': 0.0,\n",
       "  'mosaic': 1.0,\n",
       "  'mixup': 0.0,\n",
       "  'copy_paste': 0.0,\n",
       "  'copy_paste_mode': 'flip',\n",
       "  'auto_augment': 'randaugment',\n",
       "  'erasing': 0.4,\n",
       "  'crop_fraction': 1.0,\n",
       "  'cfg': None,\n",
       "  'tracker': 'botsort.yaml'},\n",
       " 'train_metrics': {'metrics/precision(B)': 0.80279,\n",
       "  'metrics/recall(B)': 0.51299,\n",
       "  'metrics/mAP50(B)': 0.62425,\n",
       "  'metrics/mAP50-95(B)': 0.37667,\n",
       "  'val/box_loss': 1.28536,\n",
       "  'val/cls_loss': 0.843,\n",
       "  'val/dfl_loss': 0.94951,\n",
       "  'fitness': 0.40143},\n",
       " 'train_results': {'epoch': [1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158,\n",
       "   159,\n",
       "   160,\n",
       "   161,\n",
       "   162,\n",
       "   163,\n",
       "   164,\n",
       "   165,\n",
       "   166,\n",
       "   167,\n",
       "   168,\n",
       "   169,\n",
       "   170,\n",
       "   171,\n",
       "   172,\n",
       "   173,\n",
       "   174,\n",
       "   175,\n",
       "   176,\n",
       "   177,\n",
       "   178,\n",
       "   179,\n",
       "   180,\n",
       "   181,\n",
       "   182,\n",
       "   183,\n",
       "   184,\n",
       "   185,\n",
       "   186,\n",
       "   187,\n",
       "   188,\n",
       "   189,\n",
       "   190,\n",
       "   191,\n",
       "   192,\n",
       "   193,\n",
       "   194,\n",
       "   195,\n",
       "   196],\n",
       "  'time': [67.7035,\n",
       "   130.385,\n",
       "   191.747,\n",
       "   252.768,\n",
       "   313.608,\n",
       "   374.398,\n",
       "   435.08,\n",
       "   496.312,\n",
       "   557.42,\n",
       "   618.506,\n",
       "   679.605,\n",
       "   740.558,\n",
       "   801.674,\n",
       "   862.924,\n",
       "   923.394,\n",
       "   984.434,\n",
       "   1045.45,\n",
       "   1106.38,\n",
       "   1167.22,\n",
       "   1228.17,\n",
       "   1289.14,\n",
       "   1350.0,\n",
       "   1410.83,\n",
       "   1471.44,\n",
       "   1532.3,\n",
       "   1593.47,\n",
       "   1654.76,\n",
       "   1716.15,\n",
       "   1777.26,\n",
       "   1838.27,\n",
       "   1899.23,\n",
       "   1959.83,\n",
       "   2020.44,\n",
       "   2081.32,\n",
       "   2142.34,\n",
       "   2203.52,\n",
       "   2264.4,\n",
       "   2325.6,\n",
       "   2386.87,\n",
       "   2447.99,\n",
       "   2508.63,\n",
       "   2569.7,\n",
       "   2630.53,\n",
       "   2691.49,\n",
       "   2752.71,\n",
       "   2813.78,\n",
       "   2875.21,\n",
       "   2936.34,\n",
       "   2997.03,\n",
       "   3057.64,\n",
       "   3118.67,\n",
       "   3179.42,\n",
       "   3240.49,\n",
       "   3301.3,\n",
       "   3361.97,\n",
       "   3422.82,\n",
       "   3483.92,\n",
       "   3544.49,\n",
       "   3605.61,\n",
       "   3666.53,\n",
       "   3727.45,\n",
       "   3788.41,\n",
       "   3849.46,\n",
       "   3910.58,\n",
       "   3971.75,\n",
       "   4032.55,\n",
       "   4092.61,\n",
       "   4152.94,\n",
       "   4213.49,\n",
       "   4274.02,\n",
       "   4334.46,\n",
       "   4394.85,\n",
       "   4455.52,\n",
       "   4516.16,\n",
       "   4577.22,\n",
       "   4638.05,\n",
       "   4698.71,\n",
       "   4759.1,\n",
       "   4819.91,\n",
       "   4880.45,\n",
       "   4941.01,\n",
       "   5001.41,\n",
       "   5061.96,\n",
       "   5122.71,\n",
       "   5183.24,\n",
       "   5243.69,\n",
       "   5304.21,\n",
       "   5364.61,\n",
       "   5425.09,\n",
       "   5485.44,\n",
       "   5545.74,\n",
       "   5606.55,\n",
       "   5667.26,\n",
       "   5728.17,\n",
       "   5788.9,\n",
       "   5849.51,\n",
       "   5909.98,\n",
       "   5970.42,\n",
       "   6030.54,\n",
       "   6091.03,\n",
       "   6151.57,\n",
       "   6212.07,\n",
       "   6272.46,\n",
       "   6332.87,\n",
       "   6393.6,\n",
       "   6453.99,\n",
       "   6514.13,\n",
       "   6574.98,\n",
       "   6635.48,\n",
       "   6695.91,\n",
       "   6756.37,\n",
       "   6816.87,\n",
       "   6877.77,\n",
       "   6939.36,\n",
       "   7000.83,\n",
       "   7061.92,\n",
       "   7123.45,\n",
       "   7184.85,\n",
       "   7245.63,\n",
       "   7306.33,\n",
       "   7367.08,\n",
       "   7427.96,\n",
       "   7488.51,\n",
       "   7549.23,\n",
       "   7610.31,\n",
       "   7671.48,\n",
       "   7732.37,\n",
       "   7793.25,\n",
       "   7854.19,\n",
       "   7915.27,\n",
       "   7976.14,\n",
       "   8036.44,\n",
       "   8097.23,\n",
       "   8158.09,\n",
       "   8219.16,\n",
       "   8280.13,\n",
       "   8341.41,\n",
       "   8402.69,\n",
       "   8464.15,\n",
       "   8525.49,\n",
       "   8586.11,\n",
       "   8648.13,\n",
       "   8710.64,\n",
       "   8772.56,\n",
       "   8834.85,\n",
       "   8897.12,\n",
       "   8959.08,\n",
       "   9021.23,\n",
       "   9082.79,\n",
       "   9143.4,\n",
       "   9204.28,\n",
       "   9264.65,\n",
       "   9325.22,\n",
       "   9385.98,\n",
       "   9446.86,\n",
       "   9507.93,\n",
       "   9568.99,\n",
       "   9629.72,\n",
       "   9690.69,\n",
       "   9751.39,\n",
       "   9811.88,\n",
       "   9872.78,\n",
       "   9933.73,\n",
       "   9994.61,\n",
       "   10055.1,\n",
       "   10115.8,\n",
       "   10176.8,\n",
       "   10237.5,\n",
       "   10298.1,\n",
       "   10359.2,\n",
       "   10420.2,\n",
       "   10481.0,\n",
       "   10541.9,\n",
       "   10603.0,\n",
       "   10664.4,\n",
       "   10725.4,\n",
       "   10786.4,\n",
       "   10847.1,\n",
       "   10907.8,\n",
       "   10968.7,\n",
       "   11029.4,\n",
       "   11090.3,\n",
       "   11151.3,\n",
       "   11212.1,\n",
       "   11273.1,\n",
       "   11333.7,\n",
       "   11394.8,\n",
       "   11455.9,\n",
       "   11516.7,\n",
       "   11577.9,\n",
       "   11638.7,\n",
       "   11697.7,\n",
       "   11756.7,\n",
       "   11815.4,\n",
       "   11874.5,\n",
       "   11933.6],\n",
       "  'train/box_loss': [2.00148,\n",
       "   1.85867,\n",
       "   1.88402,\n",
       "   1.92447,\n",
       "   1.85442,\n",
       "   1.81398,\n",
       "   1.78342,\n",
       "   1.75023,\n",
       "   1.72574,\n",
       "   1.70554,\n",
       "   1.69557,\n",
       "   1.67951,\n",
       "   1.66921,\n",
       "   1.64625,\n",
       "   1.63197,\n",
       "   1.62325,\n",
       "   1.60729,\n",
       "   1.60853,\n",
       "   1.59743,\n",
       "   1.59884,\n",
       "   1.57625,\n",
       "   1.57635,\n",
       "   1.56849,\n",
       "   1.55401,\n",
       "   1.55259,\n",
       "   1.55643,\n",
       "   1.5439,\n",
       "   1.53228,\n",
       "   1.53203,\n",
       "   1.53102,\n",
       "   1.51792,\n",
       "   1.51856,\n",
       "   1.51355,\n",
       "   1.50132,\n",
       "   1.5004,\n",
       "   1.48908,\n",
       "   1.49035,\n",
       "   1.48592,\n",
       "   1.47983,\n",
       "   1.46863,\n",
       "   1.47467,\n",
       "   1.46173,\n",
       "   1.47234,\n",
       "   1.45879,\n",
       "   1.45955,\n",
       "   1.45684,\n",
       "   1.46201,\n",
       "   1.45356,\n",
       "   1.43584,\n",
       "   1.43863,\n",
       "   1.44586,\n",
       "   1.44059,\n",
       "   1.43122,\n",
       "   1.42706,\n",
       "   1.43184,\n",
       "   1.4256,\n",
       "   1.42812,\n",
       "   1.42398,\n",
       "   1.41222,\n",
       "   1.40875,\n",
       "   1.41991,\n",
       "   1.40674,\n",
       "   1.39635,\n",
       "   1.40066,\n",
       "   1.40072,\n",
       "   1.40086,\n",
       "   1.40133,\n",
       "   1.39625,\n",
       "   1.38265,\n",
       "   1.38515,\n",
       "   1.38605,\n",
       "   1.38482,\n",
       "   1.39176,\n",
       "   1.37529,\n",
       "   1.37803,\n",
       "   1.37719,\n",
       "   1.36826,\n",
       "   1.36844,\n",
       "   1.37125,\n",
       "   1.37041,\n",
       "   1.35798,\n",
       "   1.34797,\n",
       "   1.35571,\n",
       "   1.36105,\n",
       "   1.34836,\n",
       "   1.34957,\n",
       "   1.35318,\n",
       "   1.34777,\n",
       "   1.34183,\n",
       "   1.33535,\n",
       "   1.33541,\n",
       "   1.33934,\n",
       "   1.33721,\n",
       "   1.3326,\n",
       "   1.32047,\n",
       "   1.33346,\n",
       "   1.32437,\n",
       "   1.33017,\n",
       "   1.31908,\n",
       "   1.32063,\n",
       "   1.31107,\n",
       "   1.31818,\n",
       "   1.327,\n",
       "   1.32312,\n",
       "   1.30572,\n",
       "   1.30062,\n",
       "   1.31052,\n",
       "   1.30847,\n",
       "   1.30573,\n",
       "   1.30115,\n",
       "   1.29502,\n",
       "   1.2943,\n",
       "   1.29472,\n",
       "   1.285,\n",
       "   1.28721,\n",
       "   1.28986,\n",
       "   1.28643,\n",
       "   1.28836,\n",
       "   1.28092,\n",
       "   1.28064,\n",
       "   1.27337,\n",
       "   1.27644,\n",
       "   1.27474,\n",
       "   1.27855,\n",
       "   1.27187,\n",
       "   1.25982,\n",
       "   1.25495,\n",
       "   1.25953,\n",
       "   1.2567,\n",
       "   1.25512,\n",
       "   1.25782,\n",
       "   1.25423,\n",
       "   1.24657,\n",
       "   1.25178,\n",
       "   1.24724,\n",
       "   1.23804,\n",
       "   1.25156,\n",
       "   1.23169,\n",
       "   1.23737,\n",
       "   1.23564,\n",
       "   1.23289,\n",
       "   1.22259,\n",
       "   1.22653,\n",
       "   1.22816,\n",
       "   1.22886,\n",
       "   1.21736,\n",
       "   1.22753,\n",
       "   1.21314,\n",
       "   1.22318,\n",
       "   1.21324,\n",
       "   1.21581,\n",
       "   1.20926,\n",
       "   1.20598,\n",
       "   1.21224,\n",
       "   1.2123,\n",
       "   1.20113,\n",
       "   1.20073,\n",
       "   1.18839,\n",
       "   1.19885,\n",
       "   1.19319,\n",
       "   1.19335,\n",
       "   1.19521,\n",
       "   1.18043,\n",
       "   1.19612,\n",
       "   1.18781,\n",
       "   1.18549,\n",
       "   1.18057,\n",
       "   1.17252,\n",
       "   1.17157,\n",
       "   1.17548,\n",
       "   1.17372,\n",
       "   1.17757,\n",
       "   1.16184,\n",
       "   1.17104,\n",
       "   1.17077,\n",
       "   1.16735,\n",
       "   1.16079,\n",
       "   1.15386,\n",
       "   1.15494,\n",
       "   1.14889,\n",
       "   1.15318,\n",
       "   1.14419,\n",
       "   1.14932,\n",
       "   1.14897,\n",
       "   1.1472,\n",
       "   1.13387,\n",
       "   1.1454,\n",
       "   1.14197,\n",
       "   1.13889,\n",
       "   1.13633,\n",
       "   1.12296,\n",
       "   1.09479,\n",
       "   1.09082,\n",
       "   1.09653,\n",
       "   1.09404,\n",
       "   1.08274],\n",
       "  'train/cls_loss': [2.13188,\n",
       "   1.59034,\n",
       "   1.52863,\n",
       "   1.52447,\n",
       "   1.43985,\n",
       "   1.37788,\n",
       "   1.34715,\n",
       "   1.32113,\n",
       "   1.28768,\n",
       "   1.26176,\n",
       "   1.26188,\n",
       "   1.23824,\n",
       "   1.22744,\n",
       "   1.21408,\n",
       "   1.19737,\n",
       "   1.18611,\n",
       "   1.16912,\n",
       "   1.16879,\n",
       "   1.16111,\n",
       "   1.15943,\n",
       "   1.13692,\n",
       "   1.13466,\n",
       "   1.12455,\n",
       "   1.12049,\n",
       "   1.11762,\n",
       "   1.11509,\n",
       "   1.10528,\n",
       "   1.07972,\n",
       "   1.08843,\n",
       "   1.08936,\n",
       "   1.07586,\n",
       "   1.07502,\n",
       "   1.07287,\n",
       "   1.05456,\n",
       "   1.05321,\n",
       "   1.0497,\n",
       "   1.05042,\n",
       "   1.04898,\n",
       "   1.03501,\n",
       "   1.02105,\n",
       "   1.03293,\n",
       "   1.02535,\n",
       "   1.02972,\n",
       "   1.01907,\n",
       "   1.01461,\n",
       "   1.01495,\n",
       "   1.019,\n",
       "   1.01352,\n",
       "   0.99754,\n",
       "   0.99939,\n",
       "   1.00374,\n",
       "   1.00168,\n",
       "   0.99163,\n",
       "   0.9895,\n",
       "   0.99692,\n",
       "   0.98617,\n",
       "   0.99167,\n",
       "   0.98328,\n",
       "   0.97027,\n",
       "   0.97185,\n",
       "   0.98225,\n",
       "   0.964,\n",
       "   0.96353,\n",
       "   0.95702,\n",
       "   0.95859,\n",
       "   0.96015,\n",
       "   0.95199,\n",
       "   0.96202,\n",
       "   0.94299,\n",
       "   0.94659,\n",
       "   0.94401,\n",
       "   0.94923,\n",
       "   0.944,\n",
       "   0.93477,\n",
       "   0.9384,\n",
       "   0.93585,\n",
       "   0.9316,\n",
       "   0.9305,\n",
       "   0.92122,\n",
       "   0.92963,\n",
       "   0.91582,\n",
       "   0.91306,\n",
       "   0.9138,\n",
       "   0.91824,\n",
       "   0.91045,\n",
       "   0.91322,\n",
       "   0.90977,\n",
       "   0.90949,\n",
       "   0.90236,\n",
       "   0.89864,\n",
       "   0.90089,\n",
       "   0.90645,\n",
       "   0.89519,\n",
       "   0.89966,\n",
       "   0.88602,\n",
       "   0.88998,\n",
       "   0.88996,\n",
       "   0.88941,\n",
       "   0.88057,\n",
       "   0.88271,\n",
       "   0.87333,\n",
       "   0.8861,\n",
       "   0.88516,\n",
       "   0.87557,\n",
       "   0.87199,\n",
       "   0.86267,\n",
       "   0.86926,\n",
       "   0.86801,\n",
       "   0.86571,\n",
       "   0.86095,\n",
       "   0.86226,\n",
       "   0.86048,\n",
       "   0.85261,\n",
       "   0.85336,\n",
       "   0.85411,\n",
       "   0.84972,\n",
       "   0.84612,\n",
       "   0.85038,\n",
       "   0.84721,\n",
       "   0.84146,\n",
       "   0.8406,\n",
       "   0.83876,\n",
       "   0.84225,\n",
       "   0.83838,\n",
       "   0.83723,\n",
       "   0.82816,\n",
       "   0.82735,\n",
       "   0.82788,\n",
       "   0.83089,\n",
       "   0.82286,\n",
       "   0.82378,\n",
       "   0.81911,\n",
       "   0.82026,\n",
       "   0.81708,\n",
       "   0.81512,\n",
       "   0.81104,\n",
       "   0.81529,\n",
       "   0.80338,\n",
       "   0.80593,\n",
       "   0.80797,\n",
       "   0.80214,\n",
       "   0.79331,\n",
       "   0.799,\n",
       "   0.79683,\n",
       "   0.79454,\n",
       "   0.78858,\n",
       "   0.79875,\n",
       "   0.79243,\n",
       "   0.78653,\n",
       "   0.78455,\n",
       "   0.78449,\n",
       "   0.78355,\n",
       "   0.77625,\n",
       "   0.78274,\n",
       "   0.78235,\n",
       "   0.77769,\n",
       "   0.77022,\n",
       "   0.77043,\n",
       "   0.77213,\n",
       "   0.77531,\n",
       "   0.77111,\n",
       "   0.76968,\n",
       "   0.75746,\n",
       "   0.76831,\n",
       "   0.76715,\n",
       "   0.76349,\n",
       "   0.7612,\n",
       "   0.75706,\n",
       "   0.75579,\n",
       "   0.75621,\n",
       "   0.75657,\n",
       "   0.75359,\n",
       "   0.74503,\n",
       "   0.75017,\n",
       "   0.74664,\n",
       "   0.74509,\n",
       "   0.73835,\n",
       "   0.73916,\n",
       "   0.74059,\n",
       "   0.73246,\n",
       "   0.73819,\n",
       "   0.73086,\n",
       "   0.73027,\n",
       "   0.73228,\n",
       "   0.73785,\n",
       "   0.72026,\n",
       "   0.72844,\n",
       "   0.72765,\n",
       "   0.73011,\n",
       "   0.7224,\n",
       "   0.71852,\n",
       "   0.70106,\n",
       "   0.69233,\n",
       "   0.692,\n",
       "   0.69148,\n",
       "   0.68411],\n",
       "  'train/dfl_loss': [1.18057,\n",
       "   1.11154,\n",
       "   1.13299,\n",
       "   1.14229,\n",
       "   1.12136,\n",
       "   1.10638,\n",
       "   1.09752,\n",
       "   1.0861,\n",
       "   1.08003,\n",
       "   1.06683,\n",
       "   1.06825,\n",
       "   1.06013,\n",
       "   1.0549,\n",
       "   1.05755,\n",
       "   1.04845,\n",
       "   1.0401,\n",
       "   1.03771,\n",
       "   1.04143,\n",
       "   1.03726,\n",
       "   1.03167,\n",
       "   1.02872,\n",
       "   1.0325,\n",
       "   1.02597,\n",
       "   1.02123,\n",
       "   1.02357,\n",
       "   1.0225,\n",
       "   1.01301,\n",
       "   1.01289,\n",
       "   1.01307,\n",
       "   1.00758,\n",
       "   1.01032,\n",
       "   1.00808,\n",
       "   1.00145,\n",
       "   1.00479,\n",
       "   0.99646,\n",
       "   0.99538,\n",
       "   1.00092,\n",
       "   0.9946,\n",
       "   0.99288,\n",
       "   0.99194,\n",
       "   0.9928,\n",
       "   0.98987,\n",
       "   0.99141,\n",
       "   0.98622,\n",
       "   0.98407,\n",
       "   0.98629,\n",
       "   0.9881,\n",
       "   0.98023,\n",
       "   0.98264,\n",
       "   0.98149,\n",
       "   0.9791,\n",
       "   0.9804,\n",
       "   0.97739,\n",
       "   0.9772,\n",
       "   0.98046,\n",
       "   0.97645,\n",
       "   0.97767,\n",
       "   0.97794,\n",
       "   0.97147,\n",
       "   0.96768,\n",
       "   0.97132,\n",
       "   0.96961,\n",
       "   0.96978,\n",
       "   0.96725,\n",
       "   0.97133,\n",
       "   0.96824,\n",
       "   0.9663,\n",
       "   0.96569,\n",
       "   0.96668,\n",
       "   0.96525,\n",
       "   0.96313,\n",
       "   0.9646,\n",
       "   0.96267,\n",
       "   0.96016,\n",
       "   0.96233,\n",
       "   0.96128,\n",
       "   0.95662,\n",
       "   0.96157,\n",
       "   0.95575,\n",
       "   0.95915,\n",
       "   0.95379,\n",
       "   0.95111,\n",
       "   0.95181,\n",
       "   0.95258,\n",
       "   0.95335,\n",
       "   0.95266,\n",
       "   0.95363,\n",
       "   0.95222,\n",
       "   0.94921,\n",
       "   0.95063,\n",
       "   0.94818,\n",
       "   0.95235,\n",
       "   0.94742,\n",
       "   0.94414,\n",
       "   0.94674,\n",
       "   0.94763,\n",
       "   0.94426,\n",
       "   0.94682,\n",
       "   0.94426,\n",
       "   0.94643,\n",
       "   0.9424,\n",
       "   0.94158,\n",
       "   0.94566,\n",
       "   0.94009,\n",
       "   0.94133,\n",
       "   0.93822,\n",
       "   0.93717,\n",
       "   0.9441,\n",
       "   0.94061,\n",
       "   0.93984,\n",
       "   0.93495,\n",
       "   0.93719,\n",
       "   0.93509,\n",
       "   0.93269,\n",
       "   0.93369,\n",
       "   0.9328,\n",
       "   0.93145,\n",
       "   0.93386,\n",
       "   0.93379,\n",
       "   0.93206,\n",
       "   0.9298,\n",
       "   0.93181,\n",
       "   0.93124,\n",
       "   0.93103,\n",
       "   0.93097,\n",
       "   0.92972,\n",
       "   0.92687,\n",
       "   0.92991,\n",
       "   0.92859,\n",
       "   0.92531,\n",
       "   0.92756,\n",
       "   0.92357,\n",
       "   0.92466,\n",
       "   0.92641,\n",
       "   0.92513,\n",
       "   0.92232,\n",
       "   0.92374,\n",
       "   0.92117,\n",
       "   0.9193,\n",
       "   0.92005,\n",
       "   0.91825,\n",
       "   0.9183,\n",
       "   0.91889,\n",
       "   0.9202,\n",
       "   0.91927,\n",
       "   0.91587,\n",
       "   0.91716,\n",
       "   0.91554,\n",
       "   0.91559,\n",
       "   0.91353,\n",
       "   0.91611,\n",
       "   0.91314,\n",
       "   0.91361,\n",
       "   0.91472,\n",
       "   0.91315,\n",
       "   0.91125,\n",
       "   0.91348,\n",
       "   0.90891,\n",
       "   0.91129,\n",
       "   0.91492,\n",
       "   0.91086,\n",
       "   0.90943,\n",
       "   0.90891,\n",
       "   0.90914,\n",
       "   0.91002,\n",
       "   0.90922,\n",
       "   0.90697,\n",
       "   0.90719,\n",
       "   0.90514,\n",
       "   0.90848,\n",
       "   0.90389,\n",
       "   0.90495,\n",
       "   0.9037,\n",
       "   0.90407,\n",
       "   0.90568,\n",
       "   0.90637,\n",
       "   0.90426,\n",
       "   0.89994,\n",
       "   0.90239,\n",
       "   0.90184,\n",
       "   0.9026,\n",
       "   0.90155,\n",
       "   0.90049,\n",
       "   0.89907,\n",
       "   0.89978,\n",
       "   0.8964,\n",
       "   0.89882,\n",
       "   0.89699,\n",
       "   0.89721,\n",
       "   0.89707,\n",
       "   0.89532,\n",
       "   0.88961,\n",
       "   0.88853,\n",
       "   0.88707,\n",
       "   0.88695,\n",
       "   0.88636],\n",
       "  'metrics/precision(B)': [0.65627,\n",
       "   0.67565,\n",
       "   0.53777,\n",
       "   0.64565,\n",
       "   0.65494,\n",
       "   0.62593,\n",
       "   0.65142,\n",
       "   0.68762,\n",
       "   0.68026,\n",
       "   0.70402,\n",
       "   0.70933,\n",
       "   0.73413,\n",
       "   0.70183,\n",
       "   0.69979,\n",
       "   0.69223,\n",
       "   0.69742,\n",
       "   0.69053,\n",
       "   0.68737,\n",
       "   0.72567,\n",
       "   0.71092,\n",
       "   0.7372,\n",
       "   0.76886,\n",
       "   0.7241,\n",
       "   0.7922,\n",
       "   0.75408,\n",
       "   0.72888,\n",
       "   0.73937,\n",
       "   0.70078,\n",
       "   0.75859,\n",
       "   0.76209,\n",
       "   0.74633,\n",
       "   0.7543,\n",
       "   0.73452,\n",
       "   0.73275,\n",
       "   0.76421,\n",
       "   0.76787,\n",
       "   0.7683,\n",
       "   0.73967,\n",
       "   0.75262,\n",
       "   0.76343,\n",
       "   0.774,\n",
       "   0.75581,\n",
       "   0.7556,\n",
       "   0.74964,\n",
       "   0.78287,\n",
       "   0.79104,\n",
       "   0.76564,\n",
       "   0.747,\n",
       "   0.74759,\n",
       "   0.77731,\n",
       "   0.77429,\n",
       "   0.74999,\n",
       "   0.7628,\n",
       "   0.76354,\n",
       "   0.79052,\n",
       "   0.77083,\n",
       "   0.78348,\n",
       "   0.77333,\n",
       "   0.74898,\n",
       "   0.74293,\n",
       "   0.76979,\n",
       "   0.73912,\n",
       "   0.77033,\n",
       "   0.78177,\n",
       "   0.73758,\n",
       "   0.73217,\n",
       "   0.76397,\n",
       "   0.75026,\n",
       "   0.79822,\n",
       "   0.80488,\n",
       "   0.813,\n",
       "   0.77091,\n",
       "   0.76333,\n",
       "   0.75366,\n",
       "   0.77145,\n",
       "   0.78951,\n",
       "   0.78642,\n",
       "   0.7627,\n",
       "   0.7631,\n",
       "   0.7503,\n",
       "   0.73542,\n",
       "   0.76633,\n",
       "   0.72027,\n",
       "   0.76244,\n",
       "   0.78159,\n",
       "   0.78049,\n",
       "   0.76561,\n",
       "   0.79505,\n",
       "   0.79602,\n",
       "   0.76893,\n",
       "   0.78299,\n",
       "   0.76139,\n",
       "   0.76623,\n",
       "   0.7416,\n",
       "   0.78542,\n",
       "   0.80279,\n",
       "   0.78997,\n",
       "   0.78536,\n",
       "   0.77368,\n",
       "   0.7738,\n",
       "   0.79301,\n",
       "   0.79566,\n",
       "   0.79516,\n",
       "   0.79405,\n",
       "   0.80264,\n",
       "   0.81108,\n",
       "   0.78746,\n",
       "   0.77678,\n",
       "   0.78057,\n",
       "   0.78679,\n",
       "   0.77579,\n",
       "   0.76057,\n",
       "   0.79761,\n",
       "   0.7902,\n",
       "   0.77716,\n",
       "   0.8075,\n",
       "   0.81378,\n",
       "   0.81374,\n",
       "   0.80224,\n",
       "   0.79863,\n",
       "   0.79033,\n",
       "   0.78897,\n",
       "   0.80512,\n",
       "   0.81182,\n",
       "   0.78564,\n",
       "   0.76408,\n",
       "   0.75965,\n",
       "   0.77361,\n",
       "   0.77235,\n",
       "   0.77408,\n",
       "   0.78023,\n",
       "   0.75803,\n",
       "   0.78336,\n",
       "   0.77662,\n",
       "   0.76602,\n",
       "   0.76562,\n",
       "   0.78885,\n",
       "   0.79453,\n",
       "   0.79177,\n",
       "   0.8045,\n",
       "   0.81971,\n",
       "   0.81953,\n",
       "   0.81927,\n",
       "   0.81771,\n",
       "   0.82303,\n",
       "   0.80123,\n",
       "   0.80687,\n",
       "   0.79834,\n",
       "   0.79914,\n",
       "   0.80788,\n",
       "   0.80658,\n",
       "   0.80661,\n",
       "   0.80099,\n",
       "   0.78596,\n",
       "   0.76353,\n",
       "   0.79018,\n",
       "   0.79092,\n",
       "   0.78431,\n",
       "   0.79531,\n",
       "   0.79362,\n",
       "   0.78779,\n",
       "   0.79141,\n",
       "   0.78083,\n",
       "   0.78092,\n",
       "   0.78654,\n",
       "   0.78207,\n",
       "   0.77813,\n",
       "   0.78275,\n",
       "   0.79652,\n",
       "   0.79482,\n",
       "   0.78334,\n",
       "   0.78704,\n",
       "   0.78569,\n",
       "   0.78637,\n",
       "   0.7835,\n",
       "   0.78538,\n",
       "   0.78822,\n",
       "   0.78799,\n",
       "   0.78541,\n",
       "   0.78873,\n",
       "   0.78884,\n",
       "   0.78755,\n",
       "   0.78486,\n",
       "   0.78471,\n",
       "   0.7794,\n",
       "   0.77778,\n",
       "   0.77674,\n",
       "   0.77311,\n",
       "   0.77264,\n",
       "   0.77122,\n",
       "   0.77205,\n",
       "   0.77463,\n",
       "   0.77748,\n",
       "   0.77513,\n",
       "   0.77202,\n",
       "   0.77326],\n",
       "  'metrics/recall(B)': [0.42064,\n",
       "   0.40955,\n",
       "   0.35158,\n",
       "   0.39889,\n",
       "   0.41816,\n",
       "   0.41141,\n",
       "   0.42532,\n",
       "   0.41758,\n",
       "   0.44307,\n",
       "   0.44759,\n",
       "   0.43414,\n",
       "   0.45315,\n",
       "   0.44434,\n",
       "   0.44004,\n",
       "   0.44202,\n",
       "   0.47217,\n",
       "   0.45408,\n",
       "   0.46604,\n",
       "   0.44852,\n",
       "   0.46614,\n",
       "   0.44944,\n",
       "   0.4564,\n",
       "   0.47475,\n",
       "   0.45455,\n",
       "   0.46793,\n",
       "   0.47217,\n",
       "   0.48685,\n",
       "   0.48122,\n",
       "   0.48794,\n",
       "   0.47841,\n",
       "   0.47897,\n",
       "   0.47845,\n",
       "   0.47356,\n",
       "   0.4949,\n",
       "   0.463,\n",
       "   0.4833,\n",
       "   0.468,\n",
       "   0.49536,\n",
       "   0.48933,\n",
       "   0.48495,\n",
       "   0.48289,\n",
       "   0.49351,\n",
       "   0.49814,\n",
       "   0.50093,\n",
       "   0.4782,\n",
       "   0.48794,\n",
       "   0.49165,\n",
       "   0.50232,\n",
       "   0.49583,\n",
       "   0.49814,\n",
       "   0.50757,\n",
       "   0.50696,\n",
       "   0.49583,\n",
       "   0.50371,\n",
       "   0.4884,\n",
       "   0.50139,\n",
       "   0.48933,\n",
       "   0.50162,\n",
       "   0.50652,\n",
       "   0.50669,\n",
       "   0.50881,\n",
       "   0.51716,\n",
       "   0.50092,\n",
       "   0.49861,\n",
       "   0.52146,\n",
       "   0.51479,\n",
       "   0.51067,\n",
       "   0.51252,\n",
       "   0.49629,\n",
       "   0.4949,\n",
       "   0.49,\n",
       "   0.50974,\n",
       "   0.52507,\n",
       "   0.51577,\n",
       "   0.51438,\n",
       "   0.50105,\n",
       "   0.50464,\n",
       "   0.51345,\n",
       "   0.52319,\n",
       "   0.51206,\n",
       "   0.52783,\n",
       "   0.5187,\n",
       "   0.53144,\n",
       "   0.51716,\n",
       "   0.51953,\n",
       "   0.51289,\n",
       "   0.52269,\n",
       "   0.51278,\n",
       "   0.51531,\n",
       "   0.52319,\n",
       "   0.51042,\n",
       "   0.5218,\n",
       "   0.52365,\n",
       "   0.53803,\n",
       "   0.51299,\n",
       "   0.51299,\n",
       "   0.5116,\n",
       "   0.51252,\n",
       "   0.51716,\n",
       "   0.51725,\n",
       "   0.50232,\n",
       "   0.50696,\n",
       "   0.50557,\n",
       "   0.50928,\n",
       "   0.51345,\n",
       "   0.49981,\n",
       "   0.51577,\n",
       "   0.51577,\n",
       "   0.51252,\n",
       "   0.50836,\n",
       "   0.5116,\n",
       "   0.51567,\n",
       "   0.50696,\n",
       "   0.50974,\n",
       "   0.50835,\n",
       "   0.50603,\n",
       "   0.50557,\n",
       "   0.50603,\n",
       "   0.51299,\n",
       "   0.51322,\n",
       "   0.51067,\n",
       "   0.51855,\n",
       "   0.50788,\n",
       "   0.50788,\n",
       "   0.51507,\n",
       "   0.52458,\n",
       "   0.5292,\n",
       "   0.52551,\n",
       "   0.52244,\n",
       "   0.52285,\n",
       "   0.5167,\n",
       "   0.53471,\n",
       "   0.51531,\n",
       "   0.51438,\n",
       "   0.52458,\n",
       "   0.52319,\n",
       "   0.51067,\n",
       "   0.50881,\n",
       "   0.51206,\n",
       "   0.50788,\n",
       "   0.50191,\n",
       "   0.50278,\n",
       "   0.50251,\n",
       "   0.50139,\n",
       "   0.50232,\n",
       "   0.51206,\n",
       "   0.51113,\n",
       "   0.51484,\n",
       "   0.51391,\n",
       "   0.51067,\n",
       "   0.51345,\n",
       "   0.5146,\n",
       "   0.51711,\n",
       "   0.52134,\n",
       "   0.52968,\n",
       "   0.51763,\n",
       "   0.5167,\n",
       "   0.51994,\n",
       "   0.51484,\n",
       "   0.51546,\n",
       "   0.51999,\n",
       "   0.52089,\n",
       "   0.52319,\n",
       "   0.52273,\n",
       "   0.52273,\n",
       "   0.52458,\n",
       "   0.52319,\n",
       "   0.52412,\n",
       "   0.51746,\n",
       "   0.51948,\n",
       "   0.5232,\n",
       "   0.52087,\n",
       "   0.5218,\n",
       "   0.52134,\n",
       "   0.5218,\n",
       "   0.52108,\n",
       "   0.52041,\n",
       "   0.51994,\n",
       "   0.52116,\n",
       "   0.52226,\n",
       "   0.52155,\n",
       "   0.52087,\n",
       "   0.52285,\n",
       "   0.52238,\n",
       "   0.52505,\n",
       "   0.52365,\n",
       "   0.52412,\n",
       "   0.52458,\n",
       "   0.52319,\n",
       "   0.52412,\n",
       "   0.52458,\n",
       "   0.52597,\n",
       "   0.52597,\n",
       "   0.52505,\n",
       "   0.52644,\n",
       "   0.52551],\n",
       "  'metrics/mAP50(B)': [0.4795,\n",
       "   0.47938,\n",
       "   0.38718,\n",
       "   0.46049,\n",
       "   0.48255,\n",
       "   0.47049,\n",
       "   0.49195,\n",
       "   0.49409,\n",
       "   0.50957,\n",
       "   0.53134,\n",
       "   0.51236,\n",
       "   0.5389,\n",
       "   0.53402,\n",
       "   0.53089,\n",
       "   0.53236,\n",
       "   0.54582,\n",
       "   0.5427,\n",
       "   0.55103,\n",
       "   0.54368,\n",
       "   0.55297,\n",
       "   0.55236,\n",
       "   0.55571,\n",
       "   0.55882,\n",
       "   0.5684,\n",
       "   0.56433,\n",
       "   0.56399,\n",
       "   0.57657,\n",
       "   0.5687,\n",
       "   0.58135,\n",
       "   0.57885,\n",
       "   0.5727,\n",
       "   0.57561,\n",
       "   0.57197,\n",
       "   0.58149,\n",
       "   0.57249,\n",
       "   0.58687,\n",
       "   0.57985,\n",
       "   0.58547,\n",
       "   0.58388,\n",
       "   0.58506,\n",
       "   0.58105,\n",
       "   0.59353,\n",
       "   0.59759,\n",
       "   0.5958,\n",
       "   0.58877,\n",
       "   0.59108,\n",
       "   0.59545,\n",
       "   0.58891,\n",
       "   0.58969,\n",
       "   0.59997,\n",
       "   0.60215,\n",
       "   0.60165,\n",
       "   0.59701,\n",
       "   0.60432,\n",
       "   0.59921,\n",
       "   0.59597,\n",
       "   0.59578,\n",
       "   0.60052,\n",
       "   0.60242,\n",
       "   0.59829,\n",
       "   0.60629,\n",
       "   0.61082,\n",
       "   0.60208,\n",
       "   0.60501,\n",
       "   0.60883,\n",
       "   0.60726,\n",
       "   0.61478,\n",
       "   0.61227,\n",
       "   0.61036,\n",
       "   0.60801,\n",
       "   0.60886,\n",
       "   0.61409,\n",
       "   0.6141,\n",
       "   0.61478,\n",
       "   0.61271,\n",
       "   0.61088,\n",
       "   0.61055,\n",
       "   0.61194,\n",
       "   0.61661,\n",
       "   0.61,\n",
       "   0.61403,\n",
       "   0.62239,\n",
       "   0.61298,\n",
       "   0.61586,\n",
       "   0.61953,\n",
       "   0.61553,\n",
       "   0.61957,\n",
       "   0.61945,\n",
       "   0.62291,\n",
       "   0.62669,\n",
       "   0.62194,\n",
       "   0.62494,\n",
       "   0.62629,\n",
       "   0.62337,\n",
       "   0.62411,\n",
       "   0.62425,\n",
       "   0.62054,\n",
       "   0.62228,\n",
       "   0.62542,\n",
       "   0.62145,\n",
       "   0.61636,\n",
       "   0.61699,\n",
       "   0.61831,\n",
       "   0.61894,\n",
       "   0.62122,\n",
       "   0.6196,\n",
       "   0.622,\n",
       "   0.61877,\n",
       "   0.61617,\n",
       "   0.6165,\n",
       "   0.6168,\n",
       "   0.61791,\n",
       "   0.62067,\n",
       "   0.62178,\n",
       "   0.61988,\n",
       "   0.62237,\n",
       "   0.62322,\n",
       "   0.62231,\n",
       "   0.6213,\n",
       "   0.6196,\n",
       "   0.62087,\n",
       "   0.62443,\n",
       "   0.62436,\n",
       "   0.62335,\n",
       "   0.62435,\n",
       "   0.62122,\n",
       "   0.62532,\n",
       "   0.62432,\n",
       "   0.6226,\n",
       "   0.62107,\n",
       "   0.62112,\n",
       "   0.62148,\n",
       "   0.62206,\n",
       "   0.62043,\n",
       "   0.62033,\n",
       "   0.61908,\n",
       "   0.6196,\n",
       "   0.61774,\n",
       "   0.61768,\n",
       "   0.61803,\n",
       "   0.61903,\n",
       "   0.61846,\n",
       "   0.61732,\n",
       "   0.6174,\n",
       "   0.61758,\n",
       "   0.62114,\n",
       "   0.61991,\n",
       "   0.62034,\n",
       "   0.61994,\n",
       "   0.61862,\n",
       "   0.61915,\n",
       "   0.61915,\n",
       "   0.61892,\n",
       "   0.62107,\n",
       "   0.62051,\n",
       "   0.61984,\n",
       "   0.61918,\n",
       "   0.61931,\n",
       "   0.61934,\n",
       "   0.62024,\n",
       "   0.61959,\n",
       "   0.62038,\n",
       "   0.61874,\n",
       "   0.61809,\n",
       "   0.61794,\n",
       "   0.61718,\n",
       "   0.61609,\n",
       "   0.6157,\n",
       "   0.61634,\n",
       "   0.61725,\n",
       "   0.61601,\n",
       "   0.61648,\n",
       "   0.61677,\n",
       "   0.61659,\n",
       "   0.61584,\n",
       "   0.61552,\n",
       "   0.61489,\n",
       "   0.61592,\n",
       "   0.61515,\n",
       "   0.61615,\n",
       "   0.61524,\n",
       "   0.61516,\n",
       "   0.61478,\n",
       "   0.61618,\n",
       "   0.61583,\n",
       "   0.61515,\n",
       "   0.61597,\n",
       "   0.61589,\n",
       "   0.61534,\n",
       "   0.61576,\n",
       "   0.61593,\n",
       "   0.61629,\n",
       "   0.6164,\n",
       "   0.61585,\n",
       "   0.61509,\n",
       "   0.61527],\n",
       "  'metrics/mAP50-95(B)': [0.25034,\n",
       "   0.25518,\n",
       "   0.19409,\n",
       "   0.2367,\n",
       "   0.26183,\n",
       "   0.25533,\n",
       "   0.26232,\n",
       "   0.27419,\n",
       "   0.27539,\n",
       "   0.298,\n",
       "   0.29427,\n",
       "   0.29528,\n",
       "   0.30114,\n",
       "   0.29941,\n",
       "   0.30693,\n",
       "   0.30811,\n",
       "   0.31166,\n",
       "   0.31788,\n",
       "   0.31051,\n",
       "   0.31531,\n",
       "   0.3157,\n",
       "   0.32251,\n",
       "   0.32436,\n",
       "   0.33073,\n",
       "   0.32218,\n",
       "   0.32667,\n",
       "   0.32979,\n",
       "   0.32929,\n",
       "   0.33646,\n",
       "   0.34092,\n",
       "   0.3349,\n",
       "   0.33547,\n",
       "   0.33399,\n",
       "   0.3364,\n",
       "   0.33723,\n",
       "   0.34411,\n",
       "   0.34282,\n",
       "   0.34469,\n",
       "   0.34457,\n",
       "   0.34452,\n",
       "   0.34293,\n",
       "   0.34937,\n",
       "   0.35273,\n",
       "   0.34797,\n",
       "   0.34623,\n",
       "   0.34922,\n",
       "   0.34912,\n",
       "   0.34838,\n",
       "   0.34728,\n",
       "   0.35001,\n",
       "   0.3577,\n",
       "   0.35714,\n",
       "   0.35417,\n",
       "   0.35726,\n",
       "   0.35059,\n",
       "   0.35429,\n",
       "   0.35726,\n",
       "   0.35543,\n",
       "   0.35568,\n",
       "   0.35593,\n",
       "   0.35947,\n",
       "   0.36335,\n",
       "   0.3595,\n",
       "   0.35891,\n",
       "   0.36273,\n",
       "   0.36383,\n",
       "   0.36255,\n",
       "   0.36641,\n",
       "   0.3621,\n",
       "   0.36645,\n",
       "   0.36865,\n",
       "   0.36763,\n",
       "   0.3675,\n",
       "   0.36423,\n",
       "   0.36286,\n",
       "   0.36456,\n",
       "   0.36246,\n",
       "   0.3646,\n",
       "   0.36907,\n",
       "   0.36461,\n",
       "   0.36701,\n",
       "   0.37071,\n",
       "   0.36755,\n",
       "   0.36835,\n",
       "   0.36866,\n",
       "   0.36848,\n",
       "   0.37184,\n",
       "   0.37462,\n",
       "   0.37108,\n",
       "   0.37499,\n",
       "   0.37279,\n",
       "   0.37275,\n",
       "   0.37213,\n",
       "   0.3706,\n",
       "   0.37504,\n",
       "   0.37667,\n",
       "   0.3744,\n",
       "   0.3757,\n",
       "   0.37485,\n",
       "   0.37171,\n",
       "   0.37024,\n",
       "   0.37033,\n",
       "   0.37314,\n",
       "   0.37208,\n",
       "   0.37299,\n",
       "   0.37227,\n",
       "   0.37239,\n",
       "   0.37207,\n",
       "   0.37129,\n",
       "   0.36953,\n",
       "   0.37121,\n",
       "   0.37113,\n",
       "   0.37302,\n",
       "   0.37507,\n",
       "   0.37466,\n",
       "   0.37429,\n",
       "   0.37386,\n",
       "   0.37394,\n",
       "   0.37262,\n",
       "   0.37233,\n",
       "   0.37338,\n",
       "   0.37381,\n",
       "   0.37275,\n",
       "   0.37216,\n",
       "   0.37456,\n",
       "   0.37491,\n",
       "   0.37535,\n",
       "   0.37436,\n",
       "   0.37586,\n",
       "   0.37166,\n",
       "   0.37087,\n",
       "   0.37189,\n",
       "   0.37076,\n",
       "   0.37077,\n",
       "   0.37122,\n",
       "   0.37,\n",
       "   0.37044,\n",
       "   0.37044,\n",
       "   0.3705,\n",
       "   0.37035,\n",
       "   0.36973,\n",
       "   0.36949,\n",
       "   0.37004,\n",
       "   0.37057,\n",
       "   0.37019,\n",
       "   0.37122,\n",
       "   0.37185,\n",
       "   0.37201,\n",
       "   0.3732,\n",
       "   0.37132,\n",
       "   0.37188,\n",
       "   0.37198,\n",
       "   0.37187,\n",
       "   0.37158,\n",
       "   0.37147,\n",
       "   0.37152,\n",
       "   0.37122,\n",
       "   0.37097,\n",
       "   0.37037,\n",
       "   0.3704,\n",
       "   0.37036,\n",
       "   0.36985,\n",
       "   0.37002,\n",
       "   0.3688,\n",
       "   0.36876,\n",
       "   0.36917,\n",
       "   0.36914,\n",
       "   0.36922,\n",
       "   0.36952,\n",
       "   0.36907,\n",
       "   0.36934,\n",
       "   0.36902,\n",
       "   0.36939,\n",
       "   0.36899,\n",
       "   0.36881,\n",
       "   0.36849,\n",
       "   0.36878,\n",
       "   0.36908,\n",
       "   0.36923,\n",
       "   0.36902,\n",
       "   0.36829,\n",
       "   0.36897,\n",
       "   0.36856,\n",
       "   0.36839,\n",
       "   0.36819,\n",
       "   0.3677,\n",
       "   0.36823,\n",
       "   0.36724,\n",
       "   0.36758,\n",
       "   0.36748,\n",
       "   0.36792,\n",
       "   0.36803,\n",
       "   0.36754,\n",
       "   0.36763,\n",
       "   0.36691,\n",
       "   0.36643],\n",
       "  'val/box_loss': [1.64556,\n",
       "   1.64827,\n",
       "   1.79827,\n",
       "   1.70621,\n",
       "   1.59233,\n",
       "   1.60671,\n",
       "   1.60386,\n",
       "   1.52388,\n",
       "   1.56643,\n",
       "   1.48772,\n",
       "   1.49032,\n",
       "   1.5273,\n",
       "   1.5068,\n",
       "   1.50059,\n",
       "   1.45692,\n",
       "   1.49406,\n",
       "   1.45552,\n",
       "   1.44691,\n",
       "   1.45303,\n",
       "   1.45371,\n",
       "   1.42921,\n",
       "   1.44058,\n",
       "   1.43106,\n",
       "   1.40604,\n",
       "   1.43332,\n",
       "   1.40677,\n",
       "   1.37656,\n",
       "   1.39607,\n",
       "   1.40141,\n",
       "   1.35996,\n",
       "   1.39638,\n",
       "   1.39639,\n",
       "   1.42149,\n",
       "   1.38432,\n",
       "   1.37319,\n",
       "   1.37948,\n",
       "   1.37291,\n",
       "   1.36621,\n",
       "   1.37582,\n",
       "   1.34056,\n",
       "   1.32813,\n",
       "   1.36334,\n",
       "   1.35141,\n",
       "   1.36851,\n",
       "   1.35863,\n",
       "   1.35375,\n",
       "   1.3549,\n",
       "   1.32874,\n",
       "   1.34409,\n",
       "   1.34713,\n",
       "   1.33863,\n",
       "   1.32065,\n",
       "   1.32849,\n",
       "   1.34402,\n",
       "   1.34442,\n",
       "   1.32784,\n",
       "   1.32379,\n",
       "   1.33912,\n",
       "   1.34689,\n",
       "   1.33011,\n",
       "   1.33515,\n",
       "   1.32631,\n",
       "   1.31628,\n",
       "   1.32043,\n",
       "   1.31457,\n",
       "   1.318,\n",
       "   1.31427,\n",
       "   1.31488,\n",
       "   1.3197,\n",
       "   1.30629,\n",
       "   1.30163,\n",
       "   1.30604,\n",
       "   1.29801,\n",
       "   1.31978,\n",
       "   1.30423,\n",
       "   1.30356,\n",
       "   1.31233,\n",
       "   1.29754,\n",
       "   1.29538,\n",
       "   1.30819,\n",
       "   1.30397,\n",
       "   1.29834,\n",
       "   1.28324,\n",
       "   1.29087,\n",
       "   1.30441,\n",
       "   1.29873,\n",
       "   1.28473,\n",
       "   1.27398,\n",
       "   1.29907,\n",
       "   1.28166,\n",
       "   1.29004,\n",
       "   1.29721,\n",
       "   1.30467,\n",
       "   1.31228,\n",
       "   1.29633,\n",
       "   1.28536,\n",
       "   1.29649,\n",
       "   1.29583,\n",
       "   1.30291,\n",
       "   1.30189,\n",
       "   1.30052,\n",
       "   1.30733,\n",
       "   1.3085,\n",
       "   1.30718,\n",
       "   1.29652,\n",
       "   1.28839,\n",
       "   1.29355,\n",
       "   1.30009,\n",
       "   1.30563,\n",
       "   1.3056,\n",
       "   1.29785,\n",
       "   1.29302,\n",
       "   1.29013,\n",
       "   1.29487,\n",
       "   1.29951,\n",
       "   1.30515,\n",
       "   1.3046,\n",
       "   1.30279,\n",
       "   1.29709,\n",
       "   1.29529,\n",
       "   1.28701,\n",
       "   1.28552,\n",
       "   1.28561,\n",
       "   1.28809,\n",
       "   1.28519,\n",
       "   1.28625,\n",
       "   1.29056,\n",
       "   1.29244,\n",
       "   1.29177,\n",
       "   1.29576,\n",
       "   1.29703,\n",
       "   1.30434,\n",
       "   1.30773,\n",
       "   1.31152,\n",
       "   1.3111,\n",
       "   1.31219,\n",
       "   1.30985,\n",
       "   1.30829,\n",
       "   1.30715,\n",
       "   1.30875,\n",
       "   1.30733,\n",
       "   1.30641,\n",
       "   1.30464,\n",
       "   1.30507,\n",
       "   1.30908,\n",
       "   1.30952,\n",
       "   1.31191,\n",
       "   1.31274,\n",
       "   1.31305,\n",
       "   1.3149,\n",
       "   1.31547,\n",
       "   1.31589,\n",
       "   1.31625,\n",
       "   1.31541,\n",
       "   1.31284,\n",
       "   1.31169,\n",
       "   1.31121,\n",
       "   1.30962,\n",
       "   1.30794,\n",
       "   1.30854,\n",
       "   1.30673,\n",
       "   1.31034,\n",
       "   1.31149,\n",
       "   1.31448,\n",
       "   1.31523,\n",
       "   1.31508,\n",
       "   1.31472,\n",
       "   1.3142,\n",
       "   1.3158,\n",
       "   1.31577,\n",
       "   1.31635,\n",
       "   1.31812,\n",
       "   1.3186,\n",
       "   1.31883,\n",
       "   1.31963,\n",
       "   1.31917,\n",
       "   1.31902,\n",
       "   1.31885,\n",
       "   1.31782,\n",
       "   1.319,\n",
       "   1.31963,\n",
       "   1.31916,\n",
       "   1.321,\n",
       "   1.32213,\n",
       "   1.32155,\n",
       "   1.32227,\n",
       "   1.32152,\n",
       "   1.32217,\n",
       "   1.32194,\n",
       "   1.32282,\n",
       "   1.3235,\n",
       "   1.32364,\n",
       "   1.32402,\n",
       "   1.32461,\n",
       "   1.32614,\n",
       "   1.32599],\n",
       "  'val/cls_loss': [1.40684,\n",
       "   1.33172,\n",
       "   1.44406,\n",
       "   1.30972,\n",
       "   1.26372,\n",
       "   1.2529,\n",
       "   1.2236,\n",
       "   1.1525,\n",
       "   1.17656,\n",
       "   1.07367,\n",
       "   1.12853,\n",
       "   1.06726,\n",
       "   1.07455,\n",
       "   1.07683,\n",
       "   1.0745,\n",
       "   1.06142,\n",
       "   1.02969,\n",
       "   1.03591,\n",
       "   1.03222,\n",
       "   1.05205,\n",
       "   1.03447,\n",
       "   1.0103,\n",
       "   1.02222,\n",
       "   0.99832,\n",
       "   1.01035,\n",
       "   1.00599,\n",
       "   1.02138,\n",
       "   0.97287,\n",
       "   0.99959,\n",
       "   0.94565,\n",
       "   0.96916,\n",
       "   0.98856,\n",
       "   0.98802,\n",
       "   0.94623,\n",
       "   0.95818,\n",
       "   0.94644,\n",
       "   0.95508,\n",
       "   0.95117,\n",
       "   0.9422,\n",
       "   0.92815,\n",
       "   0.95913,\n",
       "   0.9282,\n",
       "   0.91857,\n",
       "   0.96474,\n",
       "   0.9185,\n",
       "   0.92449,\n",
       "   0.90811,\n",
       "   0.93187,\n",
       "   0.92145,\n",
       "   0.91549,\n",
       "   0.89514,\n",
       "   0.90507,\n",
       "   0.89595,\n",
       "   0.8898,\n",
       "   0.912,\n",
       "   0.89145,\n",
       "   0.89728,\n",
       "   0.91228,\n",
       "   0.90499,\n",
       "   0.88422,\n",
       "   0.90561,\n",
       "   0.88566,\n",
       "   0.88914,\n",
       "   0.91056,\n",
       "   0.8932,\n",
       "   0.89058,\n",
       "   0.89504,\n",
       "   0.87737,\n",
       "   0.88414,\n",
       "   0.88114,\n",
       "   0.86937,\n",
       "   0.86421,\n",
       "   0.86828,\n",
       "   0.88225,\n",
       "   0.88358,\n",
       "   0.86959,\n",
       "   0.87297,\n",
       "   0.8714,\n",
       "   0.86261,\n",
       "   0.85766,\n",
       "   0.87893,\n",
       "   0.86304,\n",
       "   0.86436,\n",
       "   0.86948,\n",
       "   0.89265,\n",
       "   0.86262,\n",
       "   0.85944,\n",
       "   0.84713,\n",
       "   0.85477,\n",
       "   0.84912,\n",
       "   0.83333,\n",
       "   0.85493,\n",
       "   0.85463,\n",
       "   0.85162,\n",
       "   0.84803,\n",
       "   0.843,\n",
       "   0.85452,\n",
       "   0.85828,\n",
       "   0.85576,\n",
       "   0.84964,\n",
       "   0.84693,\n",
       "   0.85237,\n",
       "   0.85637,\n",
       "   0.85103,\n",
       "   0.84738,\n",
       "   0.84802,\n",
       "   0.84467,\n",
       "   0.84904,\n",
       "   0.84967,\n",
       "   0.85354,\n",
       "   0.8555,\n",
       "   0.8535,\n",
       "   0.85318,\n",
       "   0.84967,\n",
       "   0.85041,\n",
       "   0.84423,\n",
       "   0.84273,\n",
       "   0.84233,\n",
       "   0.84327,\n",
       "   0.83829,\n",
       "   0.83976,\n",
       "   0.83509,\n",
       "   0.83744,\n",
       "   0.83992,\n",
       "   0.84246,\n",
       "   0.83832,\n",
       "   0.84296,\n",
       "   0.84254,\n",
       "   0.83809,\n",
       "   0.83588,\n",
       "   0.83804,\n",
       "   0.83993,\n",
       "   0.84688,\n",
       "   0.85116,\n",
       "   0.85166,\n",
       "   0.85152,\n",
       "   0.85394,\n",
       "   0.85077,\n",
       "   0.85072,\n",
       "   0.85448,\n",
       "   0.85188,\n",
       "   0.85005,\n",
       "   0.84707,\n",
       "   0.84835,\n",
       "   0.84873,\n",
       "   0.84869,\n",
       "   0.85156,\n",
       "   0.85222,\n",
       "   0.85414,\n",
       "   0.85567,\n",
       "   0.8538,\n",
       "   0.85218,\n",
       "   0.85056,\n",
       "   0.8514,\n",
       "   0.84981,\n",
       "   0.84842,\n",
       "   0.85098,\n",
       "   0.84965,\n",
       "   0.85123,\n",
       "   0.85445,\n",
       "   0.85341,\n",
       "   0.8558,\n",
       "   0.85384,\n",
       "   0.85333,\n",
       "   0.85398,\n",
       "   0.8554,\n",
       "   0.85475,\n",
       "   0.85337,\n",
       "   0.85568,\n",
       "   0.85359,\n",
       "   0.85503,\n",
       "   0.85674,\n",
       "   0.85491,\n",
       "   0.85543,\n",
       "   0.85439,\n",
       "   0.85656,\n",
       "   0.8566,\n",
       "   0.85745,\n",
       "   0.85788,\n",
       "   0.86151,\n",
       "   0.86402,\n",
       "   0.86395,\n",
       "   0.86679,\n",
       "   0.86756,\n",
       "   0.86714,\n",
       "   0.86869,\n",
       "   0.86894,\n",
       "   0.86917,\n",
       "   0.87061,\n",
       "   0.8687,\n",
       "   0.86931,\n",
       "   0.86936,\n",
       "   0.86849,\n",
       "   0.86911,\n",
       "   0.87245,\n",
       "   0.87006],\n",
       "  'val/dfl_loss': [1.0391,\n",
       "   1.03986,\n",
       "   1.09908,\n",
       "   1.06286,\n",
       "   1.06087,\n",
       "   1.05106,\n",
       "   1.05472,\n",
       "   1.02521,\n",
       "   1.04392,\n",
       "   1.01412,\n",
       "   1.01764,\n",
       "   1.02248,\n",
       "   1.01754,\n",
       "   1.01133,\n",
       "   1.00937,\n",
       "   1.02219,\n",
       "   0.99903,\n",
       "   0.99771,\n",
       "   1.00343,\n",
       "   1.00071,\n",
       "   1.00062,\n",
       "   1.00115,\n",
       "   0.99566,\n",
       "   0.9935,\n",
       "   0.99391,\n",
       "   0.98805,\n",
       "   0.97441,\n",
       "   0.98401,\n",
       "   0.98946,\n",
       "   0.96895,\n",
       "   0.99159,\n",
       "   0.98379,\n",
       "   0.99623,\n",
       "   0.98093,\n",
       "   0.97788,\n",
       "   0.97297,\n",
       "   0.9804,\n",
       "   0.98043,\n",
       "   0.97907,\n",
       "   0.96931,\n",
       "   0.96269,\n",
       "   0.97212,\n",
       "   0.96883,\n",
       "   0.97767,\n",
       "   0.97282,\n",
       "   0.96981,\n",
       "   0.96769,\n",
       "   0.95979,\n",
       "   0.96367,\n",
       "   0.96257,\n",
       "   0.95988,\n",
       "   0.95778,\n",
       "   0.95704,\n",
       "   0.9652,\n",
       "   0.96566,\n",
       "   0.96306,\n",
       "   0.95473,\n",
       "   0.96167,\n",
       "   0.96765,\n",
       "   0.95531,\n",
       "   0.96643,\n",
       "   0.95831,\n",
       "   0.95146,\n",
       "   0.96149,\n",
       "   0.95907,\n",
       "   0.95553,\n",
       "   0.95528,\n",
       "   0.95857,\n",
       "   0.95788,\n",
       "   0.95156,\n",
       "   0.95058,\n",
       "   0.95679,\n",
       "   0.95217,\n",
       "   0.95822,\n",
       "   0.95725,\n",
       "   0.95303,\n",
       "   0.95617,\n",
       "   0.95052,\n",
       "   0.94942,\n",
       "   0.95112,\n",
       "   0.95019,\n",
       "   0.94892,\n",
       "   0.94625,\n",
       "   0.94991,\n",
       "   0.95609,\n",
       "   0.94851,\n",
       "   0.94713,\n",
       "   0.94623,\n",
       "   0.94965,\n",
       "   0.94403,\n",
       "   0.94522,\n",
       "   0.94726,\n",
       "   0.95102,\n",
       "   0.95661,\n",
       "   0.95112,\n",
       "   0.94951,\n",
       "   0.95107,\n",
       "   0.94967,\n",
       "   0.95008,\n",
       "   0.94925,\n",
       "   0.95015,\n",
       "   0.95369,\n",
       "   0.95117,\n",
       "   0.95218,\n",
       "   0.94563,\n",
       "   0.94559,\n",
       "   0.94813,\n",
       "   0.94813,\n",
       "   0.94954,\n",
       "   0.95024,\n",
       "   0.94838,\n",
       "   0.94709,\n",
       "   0.94716,\n",
       "   0.94822,\n",
       "   0.94793,\n",
       "   0.94924,\n",
       "   0.94809,\n",
       "   0.94678,\n",
       "   0.94458,\n",
       "   0.94213,\n",
       "   0.94067,\n",
       "   0.9414,\n",
       "   0.94145,\n",
       "   0.94157,\n",
       "   0.94078,\n",
       "   0.941,\n",
       "   0.94137,\n",
       "   0.94295,\n",
       "   0.94349,\n",
       "   0.94431,\n",
       "   0.94475,\n",
       "   0.94715,\n",
       "   0.94813,\n",
       "   0.9492,\n",
       "   0.95027,\n",
       "   0.95031,\n",
       "   0.94982,\n",
       "   0.94763,\n",
       "   0.94768,\n",
       "   0.94778,\n",
       "   0.94655,\n",
       "   0.94619,\n",
       "   0.94548,\n",
       "   0.94537,\n",
       "   0.94654,\n",
       "   0.9467,\n",
       "   0.94736,\n",
       "   0.94804,\n",
       "   0.94803,\n",
       "   0.94882,\n",
       "   0.9486,\n",
       "   0.94914,\n",
       "   0.94967,\n",
       "   0.94991,\n",
       "   0.94927,\n",
       "   0.94885,\n",
       "   0.94809,\n",
       "   0.94792,\n",
       "   0.94797,\n",
       "   0.94861,\n",
       "   0.94806,\n",
       "   0.94851,\n",
       "   0.94873,\n",
       "   0.94911,\n",
       "   0.94955,\n",
       "   0.94953,\n",
       "   0.94973,\n",
       "   0.94962,\n",
       "   0.95016,\n",
       "   0.95035,\n",
       "   0.95021,\n",
       "   0.95045,\n",
       "   0.9504,\n",
       "   0.95053,\n",
       "   0.95034,\n",
       "   0.95032,\n",
       "   0.95034,\n",
       "   0.95036,\n",
       "   0.95006,\n",
       "   0.95019,\n",
       "   0.95023,\n",
       "   0.95026,\n",
       "   0.95044,\n",
       "   0.95098,\n",
       "   0.95092,\n",
       "   0.95116,\n",
       "   0.95111,\n",
       "   0.95131,\n",
       "   0.95152,\n",
       "   0.95138,\n",
       "   0.9516,\n",
       "   0.95192,\n",
       "   0.9523,\n",
       "   0.95237,\n",
       "   0.9526,\n",
       "   0.95292],\n",
       "  'lr/pg0': [0.00332378,\n",
       "   0.00662416,\n",
       "   0.00989154,\n",
       "   0.0098515,\n",
       "   0.009802,\n",
       "   0.0097525,\n",
       "   0.009703,\n",
       "   0.0096535,\n",
       "   0.009604,\n",
       "   0.0095545,\n",
       "   0.009505,\n",
       "   0.0094555,\n",
       "   0.009406,\n",
       "   0.0093565,\n",
       "   0.009307,\n",
       "   0.0092575,\n",
       "   0.009208,\n",
       "   0.0091585,\n",
       "   0.009109,\n",
       "   0.0090595,\n",
       "   0.00901,\n",
       "   0.0089605,\n",
       "   0.008911,\n",
       "   0.0088615,\n",
       "   0.008812,\n",
       "   0.0087625,\n",
       "   0.008713,\n",
       "   0.0086635,\n",
       "   0.008614,\n",
       "   0.0085645,\n",
       "   0.008515,\n",
       "   0.0084655,\n",
       "   0.008416,\n",
       "   0.0083665,\n",
       "   0.008317,\n",
       "   0.0082675,\n",
       "   0.008218,\n",
       "   0.0081685,\n",
       "   0.008119,\n",
       "   0.0080695,\n",
       "   0.00802,\n",
       "   0.0079705,\n",
       "   0.007921,\n",
       "   0.0078715,\n",
       "   0.007822,\n",
       "   0.0077725,\n",
       "   0.007723,\n",
       "   0.0076735,\n",
       "   0.007624,\n",
       "   0.0075745,\n",
       "   0.007525,\n",
       "   0.0074755,\n",
       "   0.007426,\n",
       "   0.0073765,\n",
       "   0.007327,\n",
       "   0.0072775,\n",
       "   0.007228,\n",
       "   0.0071785,\n",
       "   0.007129,\n",
       "   0.0070795,\n",
       "   0.00703,\n",
       "   0.0069805,\n",
       "   0.006931,\n",
       "   0.0068815,\n",
       "   0.006832,\n",
       "   0.0067825,\n",
       "   0.006733,\n",
       "   0.0066835,\n",
       "   0.006634,\n",
       "   0.0065845,\n",
       "   0.006535,\n",
       "   0.0064855,\n",
       "   0.006436,\n",
       "   0.0063865,\n",
       "   0.006337,\n",
       "   0.0062875,\n",
       "   0.006238,\n",
       "   0.0061885,\n",
       "   0.006139,\n",
       "   0.0060895,\n",
       "   0.00604,\n",
       "   0.0059905,\n",
       "   0.005941,\n",
       "   0.0058915,\n",
       "   0.005842,\n",
       "   0.0057925,\n",
       "   0.005743,\n",
       "   0.0056935,\n",
       "   0.005644,\n",
       "   0.0055945,\n",
       "   0.005545,\n",
       "   0.0054955,\n",
       "   0.005446,\n",
       "   0.0053965,\n",
       "   0.005347,\n",
       "   0.0052975,\n",
       "   0.005248,\n",
       "   0.0051985,\n",
       "   0.005149,\n",
       "   0.0050995,\n",
       "   0.00505,\n",
       "   0.0050005,\n",
       "   0.004951,\n",
       "   0.0049015,\n",
       "   0.004852,\n",
       "   0.0048025,\n",
       "   0.004753,\n",
       "   0.0047035,\n",
       "   0.004654,\n",
       "   0.0046045,\n",
       "   0.004555,\n",
       "   0.0045055,\n",
       "   0.004456,\n",
       "   0.0044065,\n",
       "   0.004357,\n",
       "   0.0043075,\n",
       "   0.004258,\n",
       "   0.0042085,\n",
       "   0.004159,\n",
       "   0.0041095,\n",
       "   0.00406,\n",
       "   0.0040105,\n",
       "   0.003961,\n",
       "   0.0039115,\n",
       "   0.003862,\n",
       "   0.0038125,\n",
       "   0.003763,\n",
       "   0.0037135,\n",
       "   0.003664,\n",
       "   0.0036145,\n",
       "   0.003565,\n",
       "   0.0035155,\n",
       "   0.003466,\n",
       "   0.0034165,\n",
       "   0.003367,\n",
       "   0.0033175,\n",
       "   0.003268,\n",
       "   0.0032185,\n",
       "   0.003169,\n",
       "   0.0031195,\n",
       "   0.00307,\n",
       "   0.0030205,\n",
       "   0.002971,\n",
       "   0.0029215,\n",
       "   0.002872,\n",
       "   0.0028225,\n",
       "   0.002773,\n",
       "   0.0027235,\n",
       "   0.002674,\n",
       "   0.0026245,\n",
       "   0.002575,\n",
       "   0.0025255,\n",
       "   0.002476,\n",
       "   0.0024265,\n",
       "   0.002377,\n",
       "   0.0023275,\n",
       "   0.002278,\n",
       "   0.0022285,\n",
       "   0.002179,\n",
       "   0.0021295,\n",
       "   0.00208,\n",
       "   0.0020305,\n",
       "   0.001981,\n",
       "   0.0019315,\n",
       "   0.001882,\n",
       "   0.0018325,\n",
       "   0.001783,\n",
       "   0.0017335,\n",
       "   0.001684,\n",
       "   0.0016345,\n",
       "   0.001585,\n",
       "   0.0015355,\n",
       "   0.001486,\n",
       "   0.0014365,\n",
       "   0.001387,\n",
       "   0.0013375,\n",
       "   0.001288,\n",
       "   0.0012385,\n",
       "   0.001189,\n",
       "   0.0011395,\n",
       "   0.00109,\n",
       "   0.0010405,\n",
       "   0.000991,\n",
       "   0.0009415,\n",
       "   0.000892,\n",
       "   0.0008425,\n",
       "   0.000793,\n",
       "   0.0007435,\n",
       "   0.000694,\n",
       "   0.0006445,\n",
       "   0.000595,\n",
       "   0.0005455,\n",
       "   0.000496,\n",
       "   0.0004465,\n",
       "   0.000397,\n",
       "   0.0003475],\n",
       "  'lr/pg1': [0.00332378,\n",
       "   0.00662416,\n",
       "   0.00989154,\n",
       "   0.0098515,\n",
       "   0.009802,\n",
       "   0.0097525,\n",
       "   0.009703,\n",
       "   0.0096535,\n",
       "   0.009604,\n",
       "   0.0095545,\n",
       "   0.009505,\n",
       "   0.0094555,\n",
       "   0.009406,\n",
       "   0.0093565,\n",
       "   0.009307,\n",
       "   0.0092575,\n",
       "   0.009208,\n",
       "   0.0091585,\n",
       "   0.009109,\n",
       "   0.0090595,\n",
       "   0.00901,\n",
       "   0.0089605,\n",
       "   0.008911,\n",
       "   0.0088615,\n",
       "   0.008812,\n",
       "   0.0087625,\n",
       "   0.008713,\n",
       "   0.0086635,\n",
       "   0.008614,\n",
       "   0.0085645,\n",
       "   0.008515,\n",
       "   0.0084655,\n",
       "   0.008416,\n",
       "   0.0083665,\n",
       "   0.008317,\n",
       "   0.0082675,\n",
       "   0.008218,\n",
       "   0.0081685,\n",
       "   0.008119,\n",
       "   0.0080695,\n",
       "   0.00802,\n",
       "   0.0079705,\n",
       "   0.007921,\n",
       "   0.0078715,\n",
       "   0.007822,\n",
       "   0.0077725,\n",
       "   0.007723,\n",
       "   0.0076735,\n",
       "   0.007624,\n",
       "   0.0075745,\n",
       "   0.007525,\n",
       "   0.0074755,\n",
       "   0.007426,\n",
       "   0.0073765,\n",
       "   0.007327,\n",
       "   0.0072775,\n",
       "   0.007228,\n",
       "   0.0071785,\n",
       "   0.007129,\n",
       "   0.0070795,\n",
       "   0.00703,\n",
       "   0.0069805,\n",
       "   0.006931,\n",
       "   0.0068815,\n",
       "   0.006832,\n",
       "   0.0067825,\n",
       "   0.006733,\n",
       "   0.0066835,\n",
       "   0.006634,\n",
       "   0.0065845,\n",
       "   0.006535,\n",
       "   0.0064855,\n",
       "   0.006436,\n",
       "   0.0063865,\n",
       "   0.006337,\n",
       "   0.0062875,\n",
       "   0.006238,\n",
       "   0.0061885,\n",
       "   0.006139,\n",
       "   0.0060895,\n",
       "   0.00604,\n",
       "   0.0059905,\n",
       "   0.005941,\n",
       "   0.0058915,\n",
       "   0.005842,\n",
       "   0.0057925,\n",
       "   0.005743,\n",
       "   0.0056935,\n",
       "   0.005644,\n",
       "   0.0055945,\n",
       "   0.005545,\n",
       "   0.0054955,\n",
       "   0.005446,\n",
       "   0.0053965,\n",
       "   0.005347,\n",
       "   0.0052975,\n",
       "   0.005248,\n",
       "   0.0051985,\n",
       "   0.005149,\n",
       "   0.0050995,\n",
       "   0.00505,\n",
       "   0.0050005,\n",
       "   0.004951,\n",
       "   0.0049015,\n",
       "   0.004852,\n",
       "   0.0048025,\n",
       "   0.004753,\n",
       "   0.0047035,\n",
       "   0.004654,\n",
       "   0.0046045,\n",
       "   0.004555,\n",
       "   0.0045055,\n",
       "   0.004456,\n",
       "   0.0044065,\n",
       "   0.004357,\n",
       "   0.0043075,\n",
       "   0.004258,\n",
       "   0.0042085,\n",
       "   0.004159,\n",
       "   0.0041095,\n",
       "   0.00406,\n",
       "   0.0040105,\n",
       "   0.003961,\n",
       "   0.0039115,\n",
       "   0.003862,\n",
       "   0.0038125,\n",
       "   0.003763,\n",
       "   0.0037135,\n",
       "   0.003664,\n",
       "   0.0036145,\n",
       "   0.003565,\n",
       "   0.0035155,\n",
       "   0.003466,\n",
       "   0.0034165,\n",
       "   0.003367,\n",
       "   0.0033175,\n",
       "   0.003268,\n",
       "   0.0032185,\n",
       "   0.003169,\n",
       "   0.0031195,\n",
       "   0.00307,\n",
       "   0.0030205,\n",
       "   0.002971,\n",
       "   0.0029215,\n",
       "   0.002872,\n",
       "   0.0028225,\n",
       "   0.002773,\n",
       "   0.0027235,\n",
       "   0.002674,\n",
       "   0.0026245,\n",
       "   0.002575,\n",
       "   0.0025255,\n",
       "   0.002476,\n",
       "   0.0024265,\n",
       "   0.002377,\n",
       "   0.0023275,\n",
       "   0.002278,\n",
       "   0.0022285,\n",
       "   0.002179,\n",
       "   0.0021295,\n",
       "   0.00208,\n",
       "   0.0020305,\n",
       "   0.001981,\n",
       "   0.0019315,\n",
       "   0.001882,\n",
       "   0.0018325,\n",
       "   0.001783,\n",
       "   0.0017335,\n",
       "   0.001684,\n",
       "   0.0016345,\n",
       "   0.001585,\n",
       "   0.0015355,\n",
       "   0.001486,\n",
       "   0.0014365,\n",
       "   0.001387,\n",
       "   0.0013375,\n",
       "   0.001288,\n",
       "   0.0012385,\n",
       "   0.001189,\n",
       "   0.0011395,\n",
       "   0.00109,\n",
       "   0.0010405,\n",
       "   0.000991,\n",
       "   0.0009415,\n",
       "   0.000892,\n",
       "   0.0008425,\n",
       "   0.000793,\n",
       "   0.0007435,\n",
       "   0.000694,\n",
       "   0.0006445,\n",
       "   0.000595,\n",
       "   0.0005455,\n",
       "   0.000496,\n",
       "   0.0004465,\n",
       "   0.000397,\n",
       "   0.0003475],\n",
       "  'lr/pg2': [0.00332378,\n",
       "   0.00662416,\n",
       "   0.00989154,\n",
       "   0.0098515,\n",
       "   0.009802,\n",
       "   0.0097525,\n",
       "   0.009703,\n",
       "   0.0096535,\n",
       "   0.009604,\n",
       "   0.0095545,\n",
       "   0.009505,\n",
       "   0.0094555,\n",
       "   0.009406,\n",
       "   0.0093565,\n",
       "   0.009307,\n",
       "   0.0092575,\n",
       "   0.009208,\n",
       "   0.0091585,\n",
       "   0.009109,\n",
       "   0.0090595,\n",
       "   0.00901,\n",
       "   0.0089605,\n",
       "   0.008911,\n",
       "   0.0088615,\n",
       "   0.008812,\n",
       "   0.0087625,\n",
       "   0.008713,\n",
       "   0.0086635,\n",
       "   0.008614,\n",
       "   0.0085645,\n",
       "   0.008515,\n",
       "   0.0084655,\n",
       "   0.008416,\n",
       "   0.0083665,\n",
       "   0.008317,\n",
       "   0.0082675,\n",
       "   0.008218,\n",
       "   0.0081685,\n",
       "   0.008119,\n",
       "   0.0080695,\n",
       "   0.00802,\n",
       "   0.0079705,\n",
       "   0.007921,\n",
       "   0.0078715,\n",
       "   0.007822,\n",
       "   0.0077725,\n",
       "   0.007723,\n",
       "   0.0076735,\n",
       "   0.007624,\n",
       "   0.0075745,\n",
       "   0.007525,\n",
       "   0.0074755,\n",
       "   0.007426,\n",
       "   0.0073765,\n",
       "   0.007327,\n",
       "   0.0072775,\n",
       "   0.007228,\n",
       "   0.0071785,\n",
       "   0.007129,\n",
       "   0.0070795,\n",
       "   0.00703,\n",
       "   0.0069805,\n",
       "   0.006931,\n",
       "   0.0068815,\n",
       "   0.006832,\n",
       "   0.0067825,\n",
       "   0.006733,\n",
       "   0.0066835,\n",
       "   0.006634,\n",
       "   0.0065845,\n",
       "   0.006535,\n",
       "   0.0064855,\n",
       "   0.006436,\n",
       "   0.0063865,\n",
       "   0.006337,\n",
       "   0.0062875,\n",
       "   0.006238,\n",
       "   0.0061885,\n",
       "   0.006139,\n",
       "   0.0060895,\n",
       "   0.00604,\n",
       "   0.0059905,\n",
       "   0.005941,\n",
       "   0.0058915,\n",
       "   0.005842,\n",
       "   0.0057925,\n",
       "   0.005743,\n",
       "   0.0056935,\n",
       "   0.005644,\n",
       "   0.0055945,\n",
       "   0.005545,\n",
       "   0.0054955,\n",
       "   0.005446,\n",
       "   0.0053965,\n",
       "   0.005347,\n",
       "   0.0052975,\n",
       "   0.005248,\n",
       "   0.0051985,\n",
       "   0.005149,\n",
       "   0.0050995,\n",
       "   0.00505,\n",
       "   0.0050005,\n",
       "   0.004951,\n",
       "   0.0049015,\n",
       "   0.004852,\n",
       "   0.0048025,\n",
       "   0.004753,\n",
       "   0.0047035,\n",
       "   0.004654,\n",
       "   0.0046045,\n",
       "   0.004555,\n",
       "   0.0045055,\n",
       "   0.004456,\n",
       "   0.0044065,\n",
       "   0.004357,\n",
       "   0.0043075,\n",
       "   0.004258,\n",
       "   0.0042085,\n",
       "   0.004159,\n",
       "   0.0041095,\n",
       "   0.00406,\n",
       "   0.0040105,\n",
       "   0.003961,\n",
       "   0.0039115,\n",
       "   0.003862,\n",
       "   0.0038125,\n",
       "   0.003763,\n",
       "   0.0037135,\n",
       "   0.003664,\n",
       "   0.0036145,\n",
       "   0.003565,\n",
       "   0.0035155,\n",
       "   0.003466,\n",
       "   0.0034165,\n",
       "   0.003367,\n",
       "   0.0033175,\n",
       "   0.003268,\n",
       "   0.0032185,\n",
       "   0.003169,\n",
       "   0.0031195,\n",
       "   0.00307,\n",
       "   0.0030205,\n",
       "   0.002971,\n",
       "   0.0029215,\n",
       "   0.002872,\n",
       "   0.0028225,\n",
       "   0.002773,\n",
       "   0.0027235,\n",
       "   0.002674,\n",
       "   0.0026245,\n",
       "   0.002575,\n",
       "   0.0025255,\n",
       "   0.002476,\n",
       "   0.0024265,\n",
       "   0.002377,\n",
       "   0.0023275,\n",
       "   0.002278,\n",
       "   0.0022285,\n",
       "   0.002179,\n",
       "   0.0021295,\n",
       "   0.00208,\n",
       "   0.0020305,\n",
       "   0.001981,\n",
       "   0.0019315,\n",
       "   0.001882,\n",
       "   0.0018325,\n",
       "   0.001783,\n",
       "   0.0017335,\n",
       "   0.001684,\n",
       "   0.0016345,\n",
       "   0.001585,\n",
       "   0.0015355,\n",
       "   0.001486,\n",
       "   0.0014365,\n",
       "   0.001387,\n",
       "   0.0013375,\n",
       "   0.001288,\n",
       "   0.0012385,\n",
       "   0.001189,\n",
       "   0.0011395,\n",
       "   0.00109,\n",
       "   0.0010405,\n",
       "   0.000991,\n",
       "   0.0009415,\n",
       "   0.000892,\n",
       "   0.0008425,\n",
       "   0.000793,\n",
       "   0.0007435,\n",
       "   0.000694,\n",
       "   0.0006445,\n",
       "   0.000595,\n",
       "   0.0005455,\n",
       "   0.000496,\n",
       "   0.0004465,\n",
       "   0.000397,\n",
       "   0.0003475]}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model, OUTPUT_PATH)\n",
    "model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
